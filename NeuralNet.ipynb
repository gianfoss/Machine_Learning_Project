{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "abJ8gJu4dE0t"
   },
   "source": [
    "# MsCA 31009 - Machine Learning and Predictive Analytics\n",
    "\n",
    "## Project - Toxic Comment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "07AdlzCZvP7-"
   },
   "source": [
    "## Import files and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "colab_type": "code",
    "id": "1VTgVkxqTgcm",
    "outputId": "ec8821ab-d250-406a-83ba-093686e010c7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install autocorrect\n",
    "!pip3 install nltk\n",
    "!pip3 install imblearn\n",
    "!pip3 install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:08:32.584649Z",
     "start_time": "2018-11-10T21:08:25.856600Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "Y1LX4wIf40NN",
    "outputId": "98e6a84f-0765-4055-823f-f281a5e3ab6f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from autocorrect import spell\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, LSTM, Embedding, Input, GlobalMaxPool1D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q8krOKh04jgz"
   },
   "source": [
    "**Download train data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T15:02:45.835034Z",
     "start_time": "2018-11-03T15:02:44.946390Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "KxNDXLI32W2D"
   },
   "outputs": [],
   "source": [
    "toxic = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X01706nU2ZKZ"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "id": "EEr-AesYK9Cc",
    "outputId": "8225b934-c1b1-4cdd-dc30-e2217a7623b5"
   },
   "outputs": [],
   "source": [
    "toxic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zbQtFVvvzuh5"
   },
   "source": [
    "**Remove non-alphabet characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T15:02:59.725214Z",
     "start_time": "2018-11-03T15:02:56.882877Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "wWbO4_X_M9Mn"
   },
   "outputs": [],
   "source": [
    "toxic['comment_text'] = [re.sub('[^A-Za-z]', ' ', i).lower() for i in toxic['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_test['comment_text'] = [re.sub('[^A-Za-z]', ' ', i).lower() for i in toxic_test['comment_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R0uDtxCsz-d2"
   },
   "source": [
    "**Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T15:03:46.644100Z",
     "start_time": "2018-11-03T15:03:00.670428Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uiqXlNpvNeYT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "toxic['comment_text_tokenize'] = [word_tokenize(i) for i in toxic['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_test['comment_text_tokenize'] = [word_tokenize(i) for i in toxic_test['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T15:03:46.647450Z",
     "start_time": "2018-11-03T15:03:06.055Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "colab_type": "code",
    "id": "yFPqb898VJiM",
    "outputId": "7a22a2c4-1429-4f29-ce58-01f8cbc1b0dc"
   },
   "outputs": [],
   "source": [
    "toxic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yPIZm7nh0FDg"
   },
   "source": [
    "**Standardize contraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nBbBzsl2WWfI"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"cant\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dX38Bl6f0dD_"
   },
   "source": [
    "**Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fLzuow-KOUwQ"
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "stentence_placeholder = []\n",
    "for sentence in toxic.loc[:,'comment_text_tokenize']:\n",
    "    sentence_stemmed = [stemmer.stem(clean_text(word)) for word in sentence]\n",
    "    stentence_placeholder.append(sentence_stemmed)\n",
    "toxic['comment_text_tokenize_stemmed'] = stentence_placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stentence_placeholder = []\n",
    "for sentence in toxic_test.loc[:,'comment_text_tokenize']:\n",
    "    sentence_stemmed = [stemmer.stem(clean_text(word)) for word in sentence]\n",
    "    stentence_placeholder.append(sentence_stemmed)\n",
    "toxic_test['comment_text_tokenize_stemmed'] = stentence_placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ciigvcy00gSV"
   },
   "source": [
    "**Stopwords Removal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EhuRuVEoVcQk"
   },
   "outputs": [],
   "source": [
    "stentence_placeholder = []\n",
    "for sentence in toxic.loc[:,'comment_text_tokenize_stemmed']:\n",
    "    sentence_clean = [word for word in sentence if word not in stopwords.words('english')]\n",
    "    stentence_placeholder.append(sentence_clean)\n",
    "toxic['comment_text_clean'] = stentence_placeholder\n",
    "toxic['comment_text_clean'] = [' '.join(i) for i in toxic['comment_text_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scorestentence_placeholder = []\n",
    "for sentence in toxic_test.loc[:,'comment_text_tokenize_stemmed']:\n",
    "    sentence_clean = [word for word in sentence if word not in stopwords.words('english')]\n",
    "    stentence_placeholder.append(sentence_clean)\n",
    "toxic_test['comment_text_clean'] = stentence_placeholder\n",
    "toxic_test['comment_text_clean'] = [' '.join(i) for i in toxic_test['comment_text_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "mX3Rx3ZQdVks",
    "outputId": "f4e39b45-9811-4814-9e98-9b228ae1e7c2"
   },
   "outputs": [],
   "source": [
    "toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic.to_csv('train_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_test.to_csv('test_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2odG7o7L1_vY"
   },
   "source": [
    "### Create feature spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = pd.read_csv('train_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_test = pd.read_csv('test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop NA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>comment_text_tokenize</th>\n",
       "      <th>comment_text_tokenize_stemmed</th>\n",
       "      <th>comment_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>159571</td>\n",
       "      <td>159305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158250</td>\n",
       "      <td>158225</td>\n",
       "      <td>157648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>8a186dcddac73a41</td>\n",
       "      <td>jun       utc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['january']</td>\n",
       "      <td>['januari']</td>\n",
       "      <td>januari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id              comment_text          toxic  \\\n",
       "count             159571                    159571  159571.000000   \n",
       "unique            159571                    159305            NaN   \n",
       "top     8a186dcddac73a41            jun       utc             NaN   \n",
       "freq                   1                        11            NaN   \n",
       "mean                 NaN                       NaN       0.095844   \n",
       "std                  NaN                       NaN       0.294379   \n",
       "min                  NaN                       NaN       0.000000   \n",
       "25%                  NaN                       NaN       0.000000   \n",
       "50%                  NaN                       NaN       0.000000   \n",
       "75%                  NaN                       NaN       0.000000   \n",
       "max                  NaN                       NaN       1.000000   \n",
       "\n",
       "         severe_toxic        obscene         threat         insult  \\\n",
       "count   159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "unique            NaN            NaN            NaN            NaN   \n",
       "top               NaN            NaN            NaN            NaN   \n",
       "freq              NaN            NaN            NaN            NaN   \n",
       "mean         0.009996       0.052948       0.002996       0.049364   \n",
       "std          0.099477       0.223931       0.054650       0.216627   \n",
       "min          0.000000       0.000000       0.000000       0.000000   \n",
       "25%          0.000000       0.000000       0.000000       0.000000   \n",
       "50%          0.000000       0.000000       0.000000       0.000000   \n",
       "75%          0.000000       0.000000       0.000000       0.000000   \n",
       "max          1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "        identity_hate comment_text_tokenize comment_text_tokenize_stemmed  \\\n",
       "count   159571.000000                159571                        159571   \n",
       "unique            NaN                158250                        158225   \n",
       "top               NaN           ['january']                   ['januari']   \n",
       "freq              NaN                    21                            21   \n",
       "mean         0.008805                   NaN                           NaN   \n",
       "std          0.093420                   NaN                           NaN   \n",
       "min          0.000000                   NaN                           NaN   \n",
       "25%          0.000000                   NaN                           NaN   \n",
       "50%          0.000000                   NaN                           NaN   \n",
       "75%          0.000000                   NaN                           NaN   \n",
       "max          1.000000                   NaN                           NaN   \n",
       "\n",
       "       comment_text_clean  \n",
       "count              159521  \n",
       "unique             157648  \n",
       "top               januari  \n",
       "freq                   22  \n",
       "mean                  NaN  \n",
       "std                   NaN  \n",
       "min                   NaN  \n",
       "25%                   NaN  \n",
       "50%                   NaN  \n",
       "75%                   NaN  \n",
       "max                   NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(toxic.loc[:,'comment_text_clean'], toxic.iloc[:,2:8], test_size = .3, random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111664,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_submission = toxic_test.loc[:,'comment_text_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_submission = x_submission.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF Vectors as features\n",
    "\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=1000)\n",
    "tfidf_vect.fit(x_train)\n",
    "x_train_tfidf =  tfidf_vect.transform(x_train)\n",
    "x_test_tfidf =  tfidf_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_submission_tfidf = tfidf_vect.transform(x_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tfidf_os_all = []\n",
    "y_train_tfidf_os_all = []\n",
    "\n",
    "\n",
    "for i in range(6):   \n",
    "    sm_tfidf = RandomOverSampler(random_state=40)\n",
    "    x_train_tfidf_os, y_train_tfidf_os = sm_tfidf.fit_resample(x_train_tfidf, y_train.iloc[:,i])\n",
    "    x_train_tfidf_os_all.append(x_train_tfidf_os)\n",
    "    y_train_tfidf_os_all.append(y_train_tfidf_os)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:33:59.787915Z",
     "start_time": "2018-11-10T21:33:59.578615Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dim = 1000\n",
    "timesteps = 1\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(timesteps, data_dim), return_sequences=True))\n",
    "  \n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten()) \n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:34:08.703288Z",
     "start_time": "2018-11-10T21:34:08.616422Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:34:03.251014Z",
     "start_time": "2018-11-10T21:34:03.237220Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 64)             272640    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 281,025\n",
      "Trainable params: 281,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = []\n",
    "prediction_submission = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tfidf = x_test_tfidf.toarray().reshape(x_test_tfidf.shape[0], 1, x_test_tfidf.shape[1])\n",
    "x_submission_tfidf = x_submission_tfidf.toarray().reshape(x_submission_tfidf.shape[0], 1, x_submission_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:47:44.232376Z",
     "start_time": "2018-11-10T21:39:44.257993Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 181528 samples, validate on 20170 samples\n",
      "Epoch 1/20\n",
      "181528/181528 [==============================] - 9s 47us/step - loss: 0.3235 - acc: 0.8529 - val_loss: 0.3399 - val_acc: 0.8277\n",
      "Epoch 2/20\n",
      "181528/181528 [==============================] - 6s 33us/step - loss: 0.2780 - acc: 0.8755 - val_loss: 0.3312 - val_acc: 0.8332\n",
      "Epoch 3/20\n",
      "181528/181528 [==============================] - 6s 36us/step - loss: 0.2674 - acc: 0.8811 - val_loss: 0.3027 - val_acc: 0.8686\n",
      "Epoch 4/20\n",
      "181528/181528 [==============================] - 7s 37us/step - loss: 0.2585 - acc: 0.8860 - val_loss: 0.2829 - val_acc: 0.8842\n",
      "Epoch 5/20\n",
      "181528/181528 [==============================] - 7s 38us/step - loss: 0.2497 - acc: 0.8908 - val_loss: 0.2677 - val_acc: 0.8912\n",
      "Epoch 6/20\n",
      "181528/181528 [==============================] - 7s 38us/step - loss: 0.2412 - acc: 0.8941 - val_loss: 0.2417 - val_acc: 0.9086\n",
      "Epoch 7/20\n",
      "181528/181528 [==============================] - 7s 41us/step - loss: 0.2327 - acc: 0.8984 - val_loss: 0.2090 - val_acc: 0.9180\n",
      "Epoch 8/20\n",
      "181528/181528 [==============================] - 7s 37us/step - loss: 0.2226 - acc: 0.9036 - val_loss: 0.2046 - val_acc: 0.9166\n",
      "Epoch 9/20\n",
      "181528/181528 [==============================] - 7s 38us/step - loss: 0.2106 - acc: 0.9077 - val_loss: 0.1660 - val_acc: 0.9300\n",
      "Epoch 10/20\n",
      "181528/181528 [==============================] - 7s 37us/step - loss: 0.1994 - acc: 0.9123 - val_loss: 0.1627 - val_acc: 0.9316\n",
      "Epoch 11/20\n",
      "181528/181528 [==============================] - 7s 37us/step - loss: 0.1878 - acc: 0.9170 - val_loss: 0.1322 - val_acc: 0.9827\n",
      "Epoch 12/20\n",
      "181528/181528 [==============================] - 7s 38us/step - loss: 0.1773 - acc: 0.9232 - val_loss: 0.1402 - val_acc: 0.9761\n",
      "Epoch 13/20\n",
      "181528/181528 [==============================] - 7s 38us/step - loss: 0.1671 - acc: 0.9293 - val_loss: 0.1328 - val_acc: 0.9791\n",
      "Epoch 14/20\n",
      "181528/181528 [==============================] - 7s 38us/step - loss: 0.1566 - acc: 0.9351 - val_loss: 0.1100 - val_acc: 0.9906\n",
      "Epoch 15/20\n",
      "181528/181528 [==============================] - 7s 39us/step - loss: 0.1483 - acc: 0.9402 - val_loss: 0.1009 - val_acc: 0.9916\n",
      "Epoch 16/20\n",
      "181528/181528 [==============================] - 7s 38us/step - loss: 0.1395 - acc: 0.9447 - val_loss: 0.0943 - val_acc: 0.9942\n",
      "Epoch 17/20\n",
      "181528/181528 [==============================] - 7s 38us/step - loss: 0.1324 - acc: 0.9476 - val_loss: 0.0848 - val_acc: 0.9948\n",
      "Epoch 18/20\n",
      "181528/181528 [==============================] - 7s 38us/step - loss: 0.1265 - acc: 0.9502 - val_loss: 0.0837 - val_acc: 0.9951\n",
      "Epoch 19/20\n",
      "181528/181528 [==============================] - 7s 38us/step - loss: 0.1195 - acc: 0.9534 - val_loss: 0.0725 - val_acc: 0.9969\n",
      "Epoch 20/20\n",
      "181528/181528 [==============================] - 7s 38us/step - loss: 0.1152 - acc: 0.9554 - val_loss: 0.0676 - val_acc: 0.9966\n",
      "Train on 198966 samples, validate on 22108 samples\n",
      "Epoch 1/20\n",
      "198966/198966 [==============================] - 8s 39us/step - loss: 0.1150 - acc: 0.9612 - val_loss: 0.0538 - val_acc: 1.0000\n",
      "Epoch 2/20\n",
      "198966/198966 [==============================] - 8s 38us/step - loss: 0.0866 - acc: 0.9730 - val_loss: 0.0385 - val_acc: 1.0000\n",
      "Epoch 3/20\n",
      "198966/198966 [==============================] - 8s 38us/step - loss: 0.0739 - acc: 0.9775 - val_loss: 0.0348 - val_acc: 1.0000\n",
      "Epoch 4/20\n",
      "198966/198966 [==============================] - 8s 38us/step - loss: 0.0656 - acc: 0.9802 - val_loss: 0.0298 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "198966/198966 [==============================] - 8s 39us/step - loss: 0.0594 - acc: 0.9816 - val_loss: 0.0242 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "198966/198966 [==============================] - 8s 39us/step - loss: 0.0544 - acc: 0.9831 - val_loss: 0.0236 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "198966/198966 [==============================] - 8s 39us/step - loss: 0.0504 - acc: 0.9842 - val_loss: 0.0250 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "198966/198966 [==============================] - 8s 38us/step - loss: 0.0464 - acc: 0.9852 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "198966/198966 [==============================] - 8s 39us/step - loss: 0.0437 - acc: 0.9864 - val_loss: 0.0222 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "198966/198966 [==============================] - 8s 39us/step - loss: 0.0417 - acc: 0.9866 - val_loss: 0.0188 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "198966/198966 [==============================] - 8s 38us/step - loss: 0.0393 - acc: 0.9874 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "198966/198966 [==============================] - 8s 39us/step - loss: 0.0382 - acc: 0.9876 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "198966/198966 [==============================] - 8s 38us/step - loss: 0.0365 - acc: 0.9881 - val_loss: 0.0171 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "198966/198966 [==============================] - 8s 38us/step - loss: 0.0352 - acc: 0.9885 - val_loss: 0.0173 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "198966/198966 [==============================] - 8s 39us/step - loss: 0.0340 - acc: 0.9887 - val_loss: 0.0149 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "198966/198966 [==============================] - 8s 38us/step - loss: 0.0335 - acc: 0.9889 - val_loss: 0.0158 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "198966/198966 [==============================] - 8s 39us/step - loss: 0.0327 - acc: 0.9889 - val_loss: 0.0161 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "198966/198966 [==============================] - 8s 39us/step - loss: 0.0320 - acc: 0.9891 - val_loss: 0.0158 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "198966/198966 [==============================] - 8s 38us/step - loss: 0.0310 - acc: 0.9896 - val_loss: 0.0149 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "198966/198966 [==============================] - 8s 38us/step - loss: 0.0305 - acc: 0.9896 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Train on 190200 samples, validate on 21134 samples\n",
      "Epoch 1/20\n",
      "190200/190200 [==============================] - 7s 39us/step - loss: 0.3346 - acc: 0.8873 - val_loss: 0.1726 - val_acc: 0.9423\n",
      "Epoch 2/20\n",
      "190200/190200 [==============================] - 7s 38us/step - loss: 0.1653 - acc: 0.9332 - val_loss: 0.1115 - val_acc: 0.9681\n",
      "Epoch 3/20\n",
      "190200/190200 [==============================] - 7s 38us/step - loss: 0.1244 - acc: 0.9502 - val_loss: 0.0767 - val_acc: 0.9804\n",
      "Epoch 4/20\n",
      "190200/190200 [==============================] - 7s 39us/step - loss: 0.1007 - acc: 0.9607 - val_loss: 0.0637 - val_acc: 0.9874\n",
      "Epoch 5/20\n",
      "190200/190200 [==============================] - 7s 38us/step - loss: 0.0860 - acc: 0.9677 - val_loss: 0.0527 - val_acc: 0.9970\n",
      "Epoch 6/20\n",
      "190200/190200 [==============================] - 7s 38us/step - loss: 0.0764 - acc: 0.9719 - val_loss: 0.0492 - val_acc: 0.9983\n",
      "Epoch 7/20\n",
      "190200/190200 [==============================] - 7s 39us/step - loss: 0.0686 - acc: 0.9752 - val_loss: 0.0426 - val_acc: 0.9983\n",
      "Epoch 8/20\n",
      "190200/190200 [==============================] - 7s 39us/step - loss: 0.0629 - acc: 0.9775 - val_loss: 0.0460 - val_acc: 0.9979\n",
      "Epoch 9/20\n",
      "190200/190200 [==============================] - 7s 39us/step - loss: 0.0589 - acc: 0.9790 - val_loss: 0.0378 - val_acc: 0.9981\n",
      "Epoch 10/20\n",
      "190200/190200 [==============================] - 7s 38us/step - loss: 0.0546 - acc: 0.9804 - val_loss: 0.0352 - val_acc: 0.9988\n",
      "Epoch 11/20\n",
      "190200/190200 [==============================] - 7s 39us/step - loss: 0.0523 - acc: 0.9812 - val_loss: 0.0348 - val_acc: 0.9986\n",
      "Epoch 12/20\n",
      "190200/190200 [==============================] - 7s 39us/step - loss: 0.0493 - acc: 0.9821 - val_loss: 0.0336 - val_acc: 0.9991\n",
      "Epoch 13/20\n",
      "190200/190200 [==============================] - 8s 39us/step - loss: 0.0466 - acc: 0.9827 - val_loss: 0.0333 - val_acc: 0.9990\n",
      "Epoch 14/20\n",
      "190200/190200 [==============================] - 7s 39us/step - loss: 0.0449 - acc: 0.9836 - val_loss: 0.0286 - val_acc: 0.9989\n",
      "Epoch 15/20\n",
      "190200/190200 [==============================] - 7s 39us/step - loss: 0.0433 - acc: 0.9837 - val_loss: 0.0299 - val_acc: 0.9989\n",
      "Epoch 16/20\n",
      "190200/190200 [==============================] - 7s 39us/step - loss: 0.0431 - acc: 0.9844 - val_loss: 0.0340 - val_acc: 0.9991\n",
      "Epoch 17/20\n",
      "190200/190200 [==============================] - 8s 39us/step - loss: 0.0419 - acc: 0.9845 - val_loss: 0.0299 - val_acc: 0.9991\n",
      "Epoch 18/20\n",
      "190200/190200 [==============================] - 7s 37us/step - loss: 0.0397 - acc: 0.9852 - val_loss: 0.0317 - val_acc: 0.9986\n",
      "Epoch 19/20\n",
      "190200/190200 [==============================] - 7s 37us/step - loss: 0.0399 - acc: 0.9848 - val_loss: 0.0314 - val_acc: 0.9989\n",
      "Epoch 20/20\n",
      "190200/190200 [==============================] - 7s 37us/step - loss: 0.0389 - acc: 0.9854 - val_loss: 0.0304 - val_acc: 0.9989\n",
      "Train on 200365 samples, validate on 22263 samples\n",
      "Epoch 1/20\n",
      "200365/200365 [==============================] - 8s 38us/step - loss: 0.1691 - acc: 0.9462 - val_loss: 0.0367 - val_acc: 0.9878\n",
      "Epoch 2/20\n",
      "200365/200365 [==============================] - 8s 38us/step - loss: 0.0546 - acc: 0.9814 - val_loss: 0.0164 - val_acc: 0.9909\n",
      "Epoch 3/20\n",
      "200365/200365 [==============================] - 8s 38us/step - loss: 0.0335 - acc: 0.9888 - val_loss: 0.0138 - val_acc: 0.9909\n",
      "Epoch 4/20\n",
      "200365/200365 [==============================] - 8s 38us/step - loss: 0.0262 - acc: 0.9909 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "200365/200365 [==============================] - 8s 38us/step - loss: 0.0207 - acc: 0.9924 - val_loss: 0.0101 - val_acc: 0.9909\n",
      "Epoch 6/20\n",
      "200365/200365 [==============================] - 8s 39us/step - loss: 0.0190 - acc: 0.9928 - val_loss: 0.0107 - val_acc: 0.9909\n",
      "Epoch 7/20\n",
      "200365/200365 [==============================] - 8s 38us/step - loss: 0.0171 - acc: 0.9935 - val_loss: 0.0109 - val_acc: 0.9909\n",
      "Epoch 8/20\n",
      "200365/200365 [==============================] - 8s 38us/step - loss: 0.0156 - acc: 0.9938 - val_loss: 0.0090 - val_acc: 0.9909\n",
      "Epoch 9/20\n",
      "200365/200365 [==============================] - 8s 38us/step - loss: 0.0151 - acc: 0.9937 - val_loss: 0.0092 - val_acc: 0.9909\n",
      "Epoch 10/20\n",
      "200365/200365 [==============================] - 8s 39us/step - loss: 0.0143 - acc: 0.9940 - val_loss: 0.0091 - val_acc: 0.9909\n",
      "Epoch 11/20\n",
      "200365/200365 [==============================] - 8s 38us/step - loss: 0.0136 - acc: 0.9942 - val_loss: 0.0109 - val_acc: 0.9909\n",
      "Epoch 12/20\n",
      "200365/200365 [==============================] - 8s 38us/step - loss: 0.0133 - acc: 0.9944 - val_loss: 0.0100 - val_acc: 0.9909\n",
      "Epoch 13/20\n",
      "200365/200365 [==============================] - 8s 38us/step - loss: 0.0128 - acc: 0.9943 - val_loss: 0.0088 - val_acc: 0.9909\n",
      "Epoch 14/20\n",
      "200365/200365 [==============================] - 8s 38us/step - loss: 0.0127 - acc: 0.9944 - val_loss: 0.0081 - val_acc: 0.9909\n",
      "Epoch 15/20\n",
      "200365/200365 [==============================] - 8s 39us/step - loss: 0.0124 - acc: 0.9943 - val_loss: 0.0099 - val_acc: 0.9909\n",
      "Epoch 16/20\n",
      "200365/200365 [==============================] - 8s 40us/step - loss: 0.0122 - acc: 0.9946 - val_loss: 0.0093 - val_acc: 0.9909\n",
      "Epoch 17/20\n",
      "200365/200365 [==============================] - 8s 39us/step - loss: 0.0123 - acc: 0.9945 - val_loss: 0.0087 - val_acc: 0.9909\n",
      "Epoch 18/20\n",
      "200365/200365 [==============================] - 8s 38us/step - loss: 0.0119 - acc: 0.9947 - val_loss: 0.0088 - val_acc: 0.9909\n",
      "Epoch 19/20\n",
      "200365/200365 [==============================] - 8s 38us/step - loss: 0.0120 - acc: 0.9943 - val_loss: 0.0095 - val_acc: 0.9909\n",
      "Epoch 20/20\n",
      "200365/200365 [==============================] - 8s 38us/step - loss: 0.0119 - acc: 0.9946 - val_loss: 0.0089 - val_acc: 0.9909\n",
      "Train on 190908 samples, validate on 21212 samples\n",
      "Epoch 1/20\n",
      "190908/190908 [==============================] - 8s 39us/step - loss: 0.4636 - acc: 0.8772 - val_loss: 0.1944 - val_acc: 0.9410\n",
      "Epoch 2/20\n",
      "190908/190908 [==============================] - 8s 40us/step - loss: 0.1948 - acc: 0.9246 - val_loss: 0.1188 - val_acc: 0.9739\n",
      "Epoch 3/20\n",
      "190908/190908 [==============================] - 7s 38us/step - loss: 0.1492 - acc: 0.9440 - val_loss: 0.0853 - val_acc: 0.9909\n",
      "Epoch 4/20\n",
      "190908/190908 [==============================] - 7s 38us/step - loss: 0.1207 - acc: 0.9563 - val_loss: 0.0609 - val_acc: 0.9986\n",
      "Epoch 5/20\n",
      "190908/190908 [==============================] - 7s 38us/step - loss: 0.1024 - acc: 0.9641 - val_loss: 0.0464 - val_acc: 0.9989\n",
      "Epoch 6/20\n",
      "190908/190908 [==============================] - 7s 38us/step - loss: 0.0909 - acc: 0.9685 - val_loss: 0.0459 - val_acc: 0.9989\n",
      "Epoch 7/20\n",
      "190908/190908 [==============================] - 7s 38us/step - loss: 0.0807 - acc: 0.9725 - val_loss: 0.0391 - val_acc: 0.9991\n",
      "Epoch 8/20\n",
      "190908/190908 [==============================] - 7s 38us/step - loss: 0.0739 - acc: 0.9752 - val_loss: 0.0392 - val_acc: 0.9997\n",
      "Epoch 9/20\n",
      "190908/190908 [==============================] - 7s 39us/step - loss: 0.0697 - acc: 0.9766 - val_loss: 0.0318 - val_acc: 0.9997\n",
      "Epoch 10/20\n",
      "190908/190908 [==============================] - 7s 38us/step - loss: 0.0648 - acc: 0.9777 - val_loss: 0.0309 - val_acc: 0.9997\n",
      "Epoch 11/20\n",
      "190908/190908 [==============================] - 7s 39us/step - loss: 0.0619 - acc: 0.9790 - val_loss: 0.0303 - val_acc: 0.9997\n",
      "Epoch 12/20\n",
      "190908/190908 [==============================] - 7s 38us/step - loss: 0.0583 - acc: 0.9797 - val_loss: 0.0283 - val_acc: 0.9997\n",
      "Epoch 13/20\n",
      "190908/190908 [==============================] - 7s 38us/step - loss: 0.0562 - acc: 0.9804 - val_loss: 0.0259 - val_acc: 0.9997\n",
      "Epoch 14/20\n",
      "190908/190908 [==============================] - 7s 38us/step - loss: 0.0536 - acc: 0.9814 - val_loss: 0.0252 - val_acc: 0.9995\n",
      "Epoch 15/20\n",
      "190908/190908 [==============================] - 7s 38us/step - loss: 0.0519 - acc: 0.9817 - val_loss: 0.0278 - val_acc: 0.9993\n",
      "Epoch 16/20\n",
      "190908/190908 [==============================] - 7s 38us/step - loss: 0.0499 - acc: 0.9825 - val_loss: 0.0260 - val_acc: 0.9995\n",
      "Epoch 17/20\n",
      "190908/190908 [==============================] - 7s 39us/step - loss: 0.0484 - acc: 0.9829 - val_loss: 0.0232 - val_acc: 0.9995\n",
      "Epoch 18/20\n",
      "190908/190908 [==============================] - 7s 38us/step - loss: 0.0461 - acc: 0.9836 - val_loss: 0.0196 - val_acc: 0.9997\n",
      "Epoch 19/20\n",
      "190908/190908 [==============================] - 7s 38us/step - loss: 0.0460 - acc: 0.9837 - val_loss: 0.0224 - val_acc: 0.9997\n",
      "Epoch 20/20\n",
      "190908/190908 [==============================] - 7s 39us/step - loss: 0.0450 - acc: 0.9842 - val_loss: 0.0234 - val_acc: 0.9997\n",
      "Train on 199188 samples, validate on 22132 samples\n",
      "Epoch 1/20\n",
      "199188/199188 [==============================] - 8s 39us/step - loss: 0.1851 - acc: 0.9414 - val_loss: 0.0518 - val_acc: 0.9993\n",
      "Epoch 2/20\n",
      "199188/199188 [==============================] - 8s 40us/step - loss: 0.0855 - acc: 0.9703 - val_loss: 0.0355 - val_acc: 0.9993\n",
      "Epoch 3/20\n",
      "199188/199188 [==============================] - 8s 39us/step - loss: 0.0604 - acc: 0.9794 - val_loss: 0.0224 - val_acc: 0.9993\n",
      "Epoch 4/20\n",
      "199188/199188 [==============================] - 8s 39us/step - loss: 0.0486 - acc: 0.9832 - val_loss: 0.0167 - val_acc: 0.9993\n",
      "Epoch 5/20\n",
      "199188/199188 [==============================] - 8s 38us/step - loss: 0.0410 - acc: 0.9855 - val_loss: 0.0181 - val_acc: 0.9993\n",
      "Epoch 6/20\n",
      "199188/199188 [==============================] - 8s 38us/step - loss: 0.0370 - acc: 0.9868 - val_loss: 0.0185 - val_acc: 0.9993\n",
      "Epoch 7/20\n",
      "199188/199188 [==============================] - 8s 38us/step - loss: 0.0341 - acc: 0.9871 - val_loss: 0.0150 - val_acc: 0.9993\n",
      "Epoch 8/20\n",
      "199188/199188 [==============================] - 8s 38us/step - loss: 0.0309 - acc: 0.9881 - val_loss: 0.0178 - val_acc: 0.9969\n",
      "Epoch 9/20\n",
      "199188/199188 [==============================] - 8s 38us/step - loss: 0.0295 - acc: 0.9887 - val_loss: 0.0132 - val_acc: 0.9993\n",
      "Epoch 10/20\n",
      "199188/199188 [==============================] - 8s 38us/step - loss: 0.0280 - acc: 0.9890 - val_loss: 0.0140 - val_acc: 0.9993\n",
      "Epoch 11/20\n",
      "199188/199188 [==============================] - 8s 39us/step - loss: 0.0263 - acc: 0.9894 - val_loss: 0.0143 - val_acc: 0.9993\n",
      "Epoch 12/20\n",
      "199188/199188 [==============================] - 8s 39us/step - loss: 0.0256 - acc: 0.9895 - val_loss: 0.0137 - val_acc: 0.9993\n",
      "Epoch 13/20\n",
      "199188/199188 [==============================] - 8s 38us/step - loss: 0.0246 - acc: 0.9899 - val_loss: 0.0143 - val_acc: 0.9993\n",
      "Epoch 14/20\n",
      "199188/199188 [==============================] - 8s 38us/step - loss: 0.0244 - acc: 0.9900 - val_loss: 0.0127 - val_acc: 0.9993\n",
      "Epoch 15/20\n",
      "199188/199188 [==============================] - 8s 38us/step - loss: 0.0237 - acc: 0.9899 - val_loss: 0.0142 - val_acc: 0.9993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "199188/199188 [==============================] - 7s 37us/step - loss: 0.0227 - acc: 0.9900 - val_loss: 0.0127 - val_acc: 0.9993\n",
      "Epoch 17/20\n",
      "199188/199188 [==============================] - 7s 37us/step - loss: 0.0229 - acc: 0.9902 - val_loss: 0.0117 - val_acc: 0.9993\n",
      "Epoch 18/20\n",
      "199188/199188 [==============================] - 8s 38us/step - loss: 0.0220 - acc: 0.9905 - val_loss: 0.0122 - val_acc: 0.9993\n",
      "Epoch 19/20\n",
      "199188/199188 [==============================] - 8s 38us/step - loss: 0.0219 - acc: 0.9903 - val_loss: 0.0132 - val_acc: 0.9993\n",
      "Epoch 20/20\n",
      "199188/199188 [==============================] - 7s 37us/step - loss: 0.0218 - acc: 0.9904 - val_loss: 0.0147 - val_acc: 0.9993\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    x_train_tfidf = x_train_tfidf_os_all[i]\n",
    "    x_train_tfidf = x_train_tfidf.toarray().reshape(x_train_tfidf.shape[0], 1, x_train_tfidf.shape[1])\n",
    "    history = model.fit(x_train_tfidf, y_train_tfidf_os_all[i],\n",
    "              batch_size=128, epochs=20,\n",
    "              verbose=1,\n",
    "              validation_split=0.1)\n",
    "    model.save('my_model' + str(i) +'.h5')\n",
    "    prediction_test.append(model.predict_proba(x_test_tfidf))\n",
    "    prediction_submission.append(model.predict_proba(x_submission_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[5.5190416e-19],\n",
       "        [1.6109453e-24],\n",
       "        [1.6417996e-14],\n",
       "        ...,\n",
       "        [5.4007669e-18],\n",
       "        [1.0000000e+00],\n",
       "        [3.3381710e-08]], dtype=float32), array([[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.98083216],\n",
       "        [0.        ]], dtype=float32), array([[0.       ],\n",
       "        [0.       ],\n",
       "        [0.       ],\n",
       "        ...,\n",
       "        [0.       ],\n",
       "        [0.9999995],\n",
       "        [0.       ]], dtype=float32), array([[0.0000000e+00],\n",
       "        [0.0000000e+00],\n",
       "        [0.0000000e+00],\n",
       "        ...,\n",
       "        [0.0000000e+00],\n",
       "        [1.9591413e-34],\n",
       "        [0.0000000e+00]], dtype=float32), array([[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.99968696],\n",
       "        [0.        ]], dtype=float32), array([[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.00040722],\n",
       "        [0.        ]], dtype=float32)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_submission_array = np.asarray(prediction_submission).reshape(6, 153164).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 6)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_submission_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9991369e-01, 1.4971228e-08, 9.9985361e-01, 2.4681628e-06,\n",
       "        9.9993050e-01, 8.0658978e-01],\n",
       "       [1.0266882e-02, 4.3951426e-21, 0.0000000e+00, 0.0000000e+00,\n",
       "        4.4095069e-26, 0.0000000e+00],\n",
       "       [1.7676908e-01, 0.0000000e+00, 5.9478807e-01, 0.0000000e+00,\n",
       "        9.8777525e-19, 0.0000000e+00],\n",
       "       ...,\n",
       "       [1.6229183e-23, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [4.6333018e-19, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [9.9302691e-01, 2.3762806e-36, 2.7801642e-01, 0.0000000e+00,\n",
       "        1.0262520e-07, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_submission_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data=prediction_submission_array,columns=['toxic','severe_toxic','obscene','threat','insult','identity_hate'], index=toxic_test['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00001cee341fdb12</th>\n",
       "      <td>9.999137e-01</td>\n",
       "      <td>1.497123e-08</td>\n",
       "      <td>9.998536e-01</td>\n",
       "      <td>2.468163e-06</td>\n",
       "      <td>9.999305e-01</td>\n",
       "      <td>8.065898e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000247867823ef7</th>\n",
       "      <td>1.026688e-02</td>\n",
       "      <td>4.395143e-21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.409507e-26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00013b17ad220c46</th>\n",
       "      <td>1.767691e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.947881e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.877752e-19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017563c3f7919a</th>\n",
       "      <td>1.308640e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017695ad8997eb</th>\n",
       "      <td>2.358867e-22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.881332e-20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.140444e-35</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001ea8717f6de06</th>\n",
       "      <td>1.032862e-14</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00024115d4cbde0f</th>\n",
       "      <td>4.020327e-11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000247e83dcc1211</th>\n",
       "      <td>8.580169e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.136559e-06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.640940e-21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00025358d4737918</th>\n",
       "      <td>7.900949e-10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00026d1092fe71cc</th>\n",
       "      <td>2.008152e-25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002eadc3b301559</th>\n",
       "      <td>1.063312e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.834425e-18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.636092e-26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002f87b16116a7f</th>\n",
       "      <td>8.098557e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003806b11932181</th>\n",
       "      <td>5.582366e-10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003e1cccfd5a40a</th>\n",
       "      <td>1.358739e-10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.773933e-38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00059ace3e3e9a53</th>\n",
       "      <td>5.838855e-06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.422235e-38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000634272d0d44eb</th>\n",
       "      <td>2.052122e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000663aff0fffc80</th>\n",
       "      <td>6.552327e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.478065e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.773040e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000689dd34e20979</th>\n",
       "      <td>1.360873e-05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000834769115370c</th>\n",
       "      <td>2.974448e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000844b52dee5f3f</th>\n",
       "      <td>5.016229e-01</td>\n",
       "      <td>1.782305e-38</td>\n",
       "      <td>7.554605e-12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.861813e-12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00084da5d4ead7aa</th>\n",
       "      <td>3.287898e-02</td>\n",
       "      <td>9.870774e-21</td>\n",
       "      <td>1.714652e-17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.284892e-04</td>\n",
       "      <td>7.466621e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00091c35fa9d0465</th>\n",
       "      <td>8.123421e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.477318e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.099955e-05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000968ce11f5ee34</th>\n",
       "      <td>4.268272e-17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.156668e-37</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0009734200a85047</th>\n",
       "      <td>2.278705e-17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00097b6214686db5</th>\n",
       "      <td>8.904779e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.492208e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.212579e-11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0009aef4bd9e1697</th>\n",
       "      <td>4.365338e-19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000a02d807ae0254</th>\n",
       "      <td>1.180307e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000a6c6d4e89b9bc</th>\n",
       "      <td>4.866666e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.947881e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.703251e-19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000bafe2080bba82</th>\n",
       "      <td>1.054274e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.119486e-38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000bf0a9894b2807</th>\n",
       "      <td>4.120850e-19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff3ae2e177b6bb3</th>\n",
       "      <td>9.078406e-06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff4109e837f7acc</th>\n",
       "      <td>2.898473e-05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.554861e-34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff4373a81ef9f2a</th>\n",
       "      <td>1.269692e-21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff460574ddbcd80</th>\n",
       "      <td>1.180041e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.588803e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.542107e-31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff4fc0a1555be5c</th>\n",
       "      <td>4.825790e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff5b9bb944d634c</th>\n",
       "      <td>1.067730e-05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff5c4a77fe0c05f</th>\n",
       "      <td>1.920200e-12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff5fb61bd637c82</th>\n",
       "      <td>5.359858e-27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff69311f306df44</th>\n",
       "      <td>4.615496e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.496696e-19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff6ad63666fb304</th>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>9.692692e-01</td>\n",
       "      <td>9.998614e-01</td>\n",
       "      <td>5.839936e-17</td>\n",
       "      <td>9.938228e-01</td>\n",
       "      <td>3.528359e-32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff7159b3ee95618</th>\n",
       "      <td>6.322168e-09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff718ffe5f05559</th>\n",
       "      <td>5.153811e-11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff7fc22a0cdccd3</th>\n",
       "      <td>3.099907e-27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff83b80284d8440</th>\n",
       "      <td>1.746701e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.515075e-38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.122773e-15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff8ef316d0c6990</th>\n",
       "      <td>2.256890e-22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff8f521a7dbcd47</th>\n",
       "      <td>2.433521e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff8f64043129fa2</th>\n",
       "      <td>2.572684e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff9d70fe0722906</th>\n",
       "      <td>1.283716e-06</td>\n",
       "      <td>2.087498e-36</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff9fa508f400ee6</th>\n",
       "      <td>4.103886e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.821952e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.353521e-12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffa3fae1890b40a</th>\n",
       "      <td>9.983108e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.812164e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.690094e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffa8a11c4378854</th>\n",
       "      <td>9.035321e-01</td>\n",
       "      <td>3.332354e-21</td>\n",
       "      <td>8.628055e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.585865e-04</td>\n",
       "      <td>7.583763e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffac2a094c8e0e2</th>\n",
       "      <td>9.999975e-01</td>\n",
       "      <td>1.701256e-03</td>\n",
       "      <td>9.999985e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.999976e-01</td>\n",
       "      <td>9.999557e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffb5451268fb5ba</th>\n",
       "      <td>2.052486e-14</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.145064e-24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffc2b34bbe61c8d</th>\n",
       "      <td>1.987158e-25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffc489742ffe69b</th>\n",
       "      <td>9.981328e-01</td>\n",
       "      <td>1.312984e-26</td>\n",
       "      <td>8.951505e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.479920e-01</td>\n",
       "      <td>1.345269e-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffcd0960ee309b5</th>\n",
       "      <td>4.574474e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.702549e-35</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.110508e-27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffd7a9a6eb32c16</th>\n",
       "      <td>1.354646e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.141502e-30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffda9e8d6fafa9e</th>\n",
       "      <td>1.622918e-23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffe8f1340a79fc2</th>\n",
       "      <td>4.633302e-19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffffce3fb183ee80</th>\n",
       "      <td>9.930269e-01</td>\n",
       "      <td>2.376281e-36</td>\n",
       "      <td>2.780164e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.026252e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         toxic  severe_toxic       obscene        threat  \\\n",
       "id                                                                         \n",
       "00001cee341fdb12  9.999137e-01  1.497123e-08  9.998536e-01  2.468163e-06   \n",
       "0000247867823ef7  1.026688e-02  4.395143e-21  0.000000e+00  0.000000e+00   \n",
       "00013b17ad220c46  1.767691e-01  0.000000e+00  5.947881e-01  0.000000e+00   \n",
       "00017563c3f7919a  1.308640e-13  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "00017695ad8997eb  2.358867e-22  0.000000e+00  5.881332e-20  0.000000e+00   \n",
       "0001ea8717f6de06  1.032862e-14  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "00024115d4cbde0f  4.020327e-11  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "000247e83dcc1211  8.580169e-01  0.000000e+00  1.136559e-06  0.000000e+00   \n",
       "00025358d4737918  7.900949e-10  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "00026d1092fe71cc  2.008152e-25  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "0002eadc3b301559  1.063312e-01  0.000000e+00  8.834425e-18  0.000000e+00   \n",
       "0002f87b16116a7f  8.098557e-08  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "0003806b11932181  5.582366e-10  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "0003e1cccfd5a40a  1.358739e-10  0.000000e+00  6.773933e-38  0.000000e+00   \n",
       "00059ace3e3e9a53  5.838855e-06  0.000000e+00  1.422235e-38  0.000000e+00   \n",
       "000634272d0d44eb  2.052122e-04  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "000663aff0fffc80  6.552327e-01  0.000000e+00  5.478065e-01  0.000000e+00   \n",
       "000689dd34e20979  1.360873e-05  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "000834769115370c  2.974448e-13  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "000844b52dee5f3f  5.016229e-01  1.782305e-38  7.554605e-12  0.000000e+00   \n",
       "00084da5d4ead7aa  3.287898e-02  9.870774e-21  1.714652e-17  0.000000e+00   \n",
       "00091c35fa9d0465  8.123421e-01  0.000000e+00  9.477318e-02  0.000000e+00   \n",
       "000968ce11f5ee34  4.268272e-17  0.000000e+00  6.156668e-37  0.000000e+00   \n",
       "0009734200a85047  2.278705e-17  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "00097b6214686db5  8.904779e-04  0.000000e+00  5.492208e-16  0.000000e+00   \n",
       "0009aef4bd9e1697  4.365338e-19  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "000a02d807ae0254  1.180307e-13  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "000a6c6d4e89b9bc  4.866666e-01  0.000000e+00  5.947881e-01  0.000000e+00   \n",
       "000bafe2080bba82  1.054274e-01  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "000bf0a9894b2807  4.120850e-19  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "...                        ...           ...           ...           ...   \n",
       "fff3ae2e177b6bb3  9.078406e-06  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "fff4109e837f7acc  2.898473e-05  0.000000e+00  3.554861e-34  0.000000e+00   \n",
       "fff4373a81ef9f2a  1.269692e-21  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "fff460574ddbcd80  1.180041e-02  0.000000e+00  5.588803e-13  0.000000e+00   \n",
       "fff4fc0a1555be5c  4.825790e-07  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "fff5b9bb944d634c  1.067730e-05  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "fff5c4a77fe0c05f  1.920200e-12  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "fff5fb61bd637c82  5.359858e-27  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "fff69311f306df44  4.615496e-01  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "fff6ad63666fb304  9.999998e-01  9.692692e-01  9.998614e-01  5.839936e-17   \n",
       "fff7159b3ee95618  6.322168e-09  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "fff718ffe5f05559  5.153811e-11  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "fff7fc22a0cdccd3  3.099907e-27  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "fff83b80284d8440  1.746701e-01  0.000000e+00  3.515075e-38  0.000000e+00   \n",
       "fff8ef316d0c6990  2.256890e-22  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "fff8f521a7dbcd47  2.433521e-04  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "fff8f64043129fa2  2.572684e-16  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "fff9d70fe0722906  1.283716e-06  2.087498e-36  0.000000e+00  0.000000e+00   \n",
       "fff9fa508f400ee6  4.103886e-01  0.000000e+00  1.821952e-08  0.000000e+00   \n",
       "fffa3fae1890b40a  9.983108e-01  0.000000e+00  8.812164e-04  0.000000e+00   \n",
       "fffa8a11c4378854  9.035321e-01  3.332354e-21  8.628055e-07  0.000000e+00   \n",
       "fffac2a094c8e0e2  9.999975e-01  1.701256e-03  9.999985e-01  0.000000e+00   \n",
       "fffb5451268fb5ba  2.052486e-14  0.000000e+00  5.145064e-24  0.000000e+00   \n",
       "fffc2b34bbe61c8d  1.987158e-25  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "fffc489742ffe69b  9.981328e-01  1.312984e-26  8.951505e-01  0.000000e+00   \n",
       "fffcd0960ee309b5  4.574474e-03  0.000000e+00  2.702549e-35  0.000000e+00   \n",
       "fffd7a9a6eb32c16  1.354646e-03  0.000000e+00  4.141502e-30  0.000000e+00   \n",
       "fffda9e8d6fafa9e  1.622918e-23  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "fffe8f1340a79fc2  4.633302e-19  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "ffffce3fb183ee80  9.930269e-01  2.376281e-36  2.780164e-01  0.000000e+00   \n",
       "\n",
       "                        insult  identity_hate  \n",
       "id                                             \n",
       "00001cee341fdb12  9.999305e-01   8.065898e-01  \n",
       "0000247867823ef7  4.409507e-26   0.000000e+00  \n",
       "00013b17ad220c46  9.877752e-19   0.000000e+00  \n",
       "00017563c3f7919a  0.000000e+00   0.000000e+00  \n",
       "00017695ad8997eb  1.140444e-35   0.000000e+00  \n",
       "0001ea8717f6de06  0.000000e+00   0.000000e+00  \n",
       "00024115d4cbde0f  0.000000e+00   0.000000e+00  \n",
       "000247e83dcc1211  7.640940e-21   0.000000e+00  \n",
       "00025358d4737918  0.000000e+00   0.000000e+00  \n",
       "00026d1092fe71cc  0.000000e+00   0.000000e+00  \n",
       "0002eadc3b301559  2.636092e-26   0.000000e+00  \n",
       "0002f87b16116a7f  0.000000e+00   0.000000e+00  \n",
       "0003806b11932181  0.000000e+00   0.000000e+00  \n",
       "0003e1cccfd5a40a  0.000000e+00   0.000000e+00  \n",
       "00059ace3e3e9a53  0.000000e+00   0.000000e+00  \n",
       "000634272d0d44eb  0.000000e+00   0.000000e+00  \n",
       "000663aff0fffc80  6.773040e-01   0.000000e+00  \n",
       "000689dd34e20979  0.000000e+00   0.000000e+00  \n",
       "000834769115370c  0.000000e+00   0.000000e+00  \n",
       "000844b52dee5f3f  5.861813e-12   0.000000e+00  \n",
       "00084da5d4ead7aa  6.284892e-04   7.466621e-19  \n",
       "00091c35fa9d0465  3.099955e-05   0.000000e+00  \n",
       "000968ce11f5ee34  0.000000e+00   0.000000e+00  \n",
       "0009734200a85047  0.000000e+00   0.000000e+00  \n",
       "00097b6214686db5  2.212579e-11   0.000000e+00  \n",
       "0009aef4bd9e1697  0.000000e+00   0.000000e+00  \n",
       "000a02d807ae0254  0.000000e+00   0.000000e+00  \n",
       "000a6c6d4e89b9bc  2.703251e-19   0.000000e+00  \n",
       "000bafe2080bba82  3.119486e-38   0.000000e+00  \n",
       "000bf0a9894b2807  0.000000e+00   0.000000e+00  \n",
       "...                        ...            ...  \n",
       "fff3ae2e177b6bb3  0.000000e+00   0.000000e+00  \n",
       "fff4109e837f7acc  0.000000e+00   0.000000e+00  \n",
       "fff4373a81ef9f2a  0.000000e+00   0.000000e+00  \n",
       "fff460574ddbcd80  8.542107e-31   0.000000e+00  \n",
       "fff4fc0a1555be5c  0.000000e+00   0.000000e+00  \n",
       "fff5b9bb944d634c  0.000000e+00   0.000000e+00  \n",
       "fff5c4a77fe0c05f  0.000000e+00   0.000000e+00  \n",
       "fff5fb61bd637c82  0.000000e+00   0.000000e+00  \n",
       "fff69311f306df44  9.496696e-19   0.000000e+00  \n",
       "fff6ad63666fb304  9.938228e-01   3.528359e-32  \n",
       "fff7159b3ee95618  0.000000e+00   0.000000e+00  \n",
       "fff718ffe5f05559  0.000000e+00   0.000000e+00  \n",
       "fff7fc22a0cdccd3  0.000000e+00   0.000000e+00  \n",
       "fff83b80284d8440  3.122773e-15   0.000000e+00  \n",
       "fff8ef316d0c6990  0.000000e+00   0.000000e+00  \n",
       "fff8f521a7dbcd47  0.000000e+00   0.000000e+00  \n",
       "fff8f64043129fa2  0.000000e+00   0.000000e+00  \n",
       "fff9d70fe0722906  0.000000e+00   0.000000e+00  \n",
       "fff9fa508f400ee6  4.353521e-12   0.000000e+00  \n",
       "fffa3fae1890b40a  2.690094e-04   0.000000e+00  \n",
       "fffa8a11c4378854  1.585865e-04   7.583763e-02  \n",
       "fffac2a094c8e0e2  9.999976e-01   9.999557e-01  \n",
       "fffb5451268fb5ba  0.000000e+00   0.000000e+00  \n",
       "fffc2b34bbe61c8d  0.000000e+00   0.000000e+00  \n",
       "fffc489742ffe69b  9.479920e-01   1.345269e-35  \n",
       "fffcd0960ee309b5  1.110508e-27   0.000000e+00  \n",
       "fffd7a9a6eb32c16  0.000000e+00   0.000000e+00  \n",
       "fffda9e8d6fafa9e  0.000000e+00   0.000000e+00  \n",
       "fffe8f1340a79fc2  0.000000e+00   0.000000e+00  \n",
       "ffffce3fb183ee80  1.026252e-07   0.000000e+00  \n",
       "\n",
       "[153164 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9306707051233531,\n",
       " 0.9538281585776786,\n",
       " 0.9561398474092062,\n",
       " 0.7975416871817973,\n",
       " 0.9280171997120963,\n",
       " 0.8327414038235497]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[roc_auc_score(y_test.iloc[:,i], prediction_test[i]) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8998231669712803"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([roc_auc_score(y_test.iloc[:,i], prediction_test[i]) for i in range(6)]) / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     43378\n",
      "           1       0.84      0.60      0.70      4479\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     47857\n",
      "   macro avg       0.90      0.79      0.84     47857\n",
      "weighted avg       0.95      0.95      0.95     47857\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.iloc[:,0], prediction_test[0] > 0.92))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data Preprocessing.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
