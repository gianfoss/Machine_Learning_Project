{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:08:32.584649Z",
     "start_time": "2018-11-10T21:08:25.856600Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "Y1LX4wIf40NN",
    "outputId": "98e6a84f-0765-4055-823f-f281a5e3ab6f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from autocorrect import spell\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, LSTM, Embedding, Input, GlobalMaxPool1D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2odG7o7L1_vY"
   },
   "source": [
    "### Create feature spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = pd.read_csv('train_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_test = pd.read_csv('test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop NA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>comment_text_tokenize</th>\n",
       "      <th>comment_text_tokenize_stemmed</th>\n",
       "      <th>comment_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>159571</td>\n",
       "      <td>159305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158250</td>\n",
       "      <td>158225</td>\n",
       "      <td>157648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>da8b4951ee7f4f03</td>\n",
       "      <td>jun       utc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['january']</td>\n",
       "      <td>['januari']</td>\n",
       "      <td>januari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id              comment_text          toxic  \\\n",
       "count             159571                    159571  159571.000000   \n",
       "unique            159571                    159305            NaN   \n",
       "top     da8b4951ee7f4f03            jun       utc             NaN   \n",
       "freq                   1                        11            NaN   \n",
       "mean                 NaN                       NaN       0.095844   \n",
       "std                  NaN                       NaN       0.294379   \n",
       "min                  NaN                       NaN       0.000000   \n",
       "25%                  NaN                       NaN       0.000000   \n",
       "50%                  NaN                       NaN       0.000000   \n",
       "75%                  NaN                       NaN       0.000000   \n",
       "max                  NaN                       NaN       1.000000   \n",
       "\n",
       "         severe_toxic        obscene         threat         insult  \\\n",
       "count   159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "unique            NaN            NaN            NaN            NaN   \n",
       "top               NaN            NaN            NaN            NaN   \n",
       "freq              NaN            NaN            NaN            NaN   \n",
       "mean         0.009996       0.052948       0.002996       0.049364   \n",
       "std          0.099477       0.223931       0.054650       0.216627   \n",
       "min          0.000000       0.000000       0.000000       0.000000   \n",
       "25%          0.000000       0.000000       0.000000       0.000000   \n",
       "50%          0.000000       0.000000       0.000000       0.000000   \n",
       "75%          0.000000       0.000000       0.000000       0.000000   \n",
       "max          1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "        identity_hate comment_text_tokenize comment_text_tokenize_stemmed  \\\n",
       "count   159571.000000                159571                        159571   \n",
       "unique            NaN                158250                        158225   \n",
       "top               NaN           ['january']                   ['januari']   \n",
       "freq              NaN                    21                            21   \n",
       "mean         0.008805                   NaN                           NaN   \n",
       "std          0.093420                   NaN                           NaN   \n",
       "min          0.000000                   NaN                           NaN   \n",
       "25%          0.000000                   NaN                           NaN   \n",
       "50%          0.000000                   NaN                           NaN   \n",
       "75%          0.000000                   NaN                           NaN   \n",
       "max          1.000000                   NaN                           NaN   \n",
       "\n",
       "       comment_text_clean  \n",
       "count              159521  \n",
       "unique             157648  \n",
       "top               januari  \n",
       "freq                   22  \n",
       "mean                  NaN  \n",
       "std                   NaN  \n",
       "min                   NaN  \n",
       "25%                   NaN  \n",
       "50%                   NaN  \n",
       "75%                   NaN  \n",
       "max                   NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(toxic.loc[:,'comment_text_clean'], toxic.iloc[:,2:8], test_size = .2, random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127616,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_submission = toxic_test.loc[:,'comment_text_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_submission = x_submission.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF Vectors as features\n",
    "\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=max_features)\n",
    "tfidf_vect.fit(x_train)\n",
    "x_train_tfidf =  tfidf_vect.transform(x_train)\n",
    "x_test_tfidf =  tfidf_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_submission_tfidf = tfidf_vect.transform(x_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tfidf_os_all = []\n",
    "y_train_tfidf_os_all = []\n",
    "\n",
    "\n",
    "for i in range(6):   \n",
    "    sm_tfidf = RandomOverSampler(random_state=40)\n",
    "    x_train_tfidf_os, y_train_tfidf_os = sm_tfidf.fit_resample(x_train_tfidf, y_train.iloc[:,i])\n",
    "    x_train_tfidf_os_all.append(x_train_tfidf_os)\n",
    "    y_train_tfidf_os_all.append(y_train_tfidf_os)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:33:59.787915Z",
     "start_time": "2018-11-10T21:33:59.578615Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dim = max_features\n",
    "timesteps = 1\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(timesteps, data_dim), return_sequences=True))\n",
    "  \n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten()) \n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:34:08.703288Z",
     "start_time": "2018-11-10T21:34:08.616422Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:34:03.251014Z",
     "start_time": "2018-11-10T21:34:03.237220Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 64)             272640    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 285,185\n",
      "Trainable params: 285,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = []\n",
    "prediction_submission = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tfidf = x_test_tfidf.toarray().reshape(x_test_tfidf.shape[0], 1, x_test_tfidf.shape[1])\n",
    "x_submission_tfidf = x_submission_tfidf.toarray().reshape(x_submission_tfidf.shape[0], 1, x_submission_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:47:44.232376Z",
     "start_time": "2018-11-10T21:39:44.257993Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 207637 samples, validate on 23071 samples\n",
      "Epoch 1/30\n",
      "207637/207637 [==============================] - 8s 40us/step - loss: 0.3324 - acc: 0.8463 - val_loss: 0.3792 - val_acc: 0.7955\n",
      "Epoch 2/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.2865 - acc: 0.8720 - val_loss: 0.3039 - val_acc: 0.8851\n",
      "Epoch 3/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.2749 - acc: 0.8781 - val_loss: 0.2576 - val_acc: 0.9094\n",
      "Epoch 4/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.2629 - acc: 0.8847 - val_loss: 0.2667 - val_acc: 0.9025\n",
      "Epoch 5/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.2490 - acc: 0.8922 - val_loss: 0.2209 - val_acc: 0.9344\n",
      "Epoch 6/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.2374 - acc: 0.8979 - val_loss: 0.2061 - val_acc: 0.9422\n",
      "Epoch 7/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.2250 - acc: 0.9035 - val_loss: 0.1869 - val_acc: 0.9604\n",
      "Epoch 8/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.2139 - acc: 0.9092 - val_loss: 0.1714 - val_acc: 0.9681\n",
      "Epoch 9/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.2041 - acc: 0.9143 - val_loss: 0.1343 - val_acc: 0.9840\n",
      "Epoch 10/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1946 - acc: 0.9193 - val_loss: 0.1341 - val_acc: 0.9851\n",
      "Epoch 11/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1858 - acc: 0.9237 - val_loss: 0.1088 - val_acc: 0.9902\n",
      "Epoch 12/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1766 - acc: 0.9280 - val_loss: 0.1150 - val_acc: 0.9904\n",
      "Epoch 13/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1698 - acc: 0.9321 - val_loss: 0.0987 - val_acc: 0.9924\n",
      "Epoch 14/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1621 - acc: 0.9354 - val_loss: 0.0920 - val_acc: 0.9941\n",
      "Epoch 15/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1551 - acc: 0.9393 - val_loss: 0.0938 - val_acc: 0.9945\n",
      "Epoch 16/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1503 - acc: 0.9415 - val_loss: 0.0809 - val_acc: 0.9978\n",
      "Epoch 17/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1430 - acc: 0.9451 - val_loss: 0.0712 - val_acc: 0.9989\n",
      "Epoch 18/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1376 - acc: 0.9478 - val_loss: 0.0736 - val_acc: 0.9979\n",
      "Epoch 19/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1321 - acc: 0.9504 - val_loss: 0.0632 - val_acc: 0.9977\n",
      "Epoch 20/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1284 - acc: 0.9521 - val_loss: 0.0686 - val_acc: 0.9982\n",
      "Epoch 21/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1238 - acc: 0.9545 - val_loss: 0.0643 - val_acc: 0.9984\n",
      "Epoch 22/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1201 - acc: 0.9560 - val_loss: 0.0573 - val_acc: 0.9977\n",
      "Epoch 23/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1159 - acc: 0.9576 - val_loss: 0.0631 - val_acc: 0.9980\n",
      "Epoch 24/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1118 - acc: 0.9591 - val_loss: 0.0530 - val_acc: 0.9986\n",
      "Epoch 25/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1094 - acc: 0.9607 - val_loss: 0.0514 - val_acc: 0.9981\n",
      "Epoch 26/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1066 - acc: 0.9617 - val_loss: 0.0600 - val_acc: 0.9970\n",
      "Epoch 27/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1039 - acc: 0.9630 - val_loss: 0.0495 - val_acc: 0.9987\n",
      "Epoch 28/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.1009 - acc: 0.9640 - val_loss: 0.0425 - val_acc: 0.9983\n",
      "Epoch 29/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.0978 - acc: 0.9653 - val_loss: 0.0415 - val_acc: 0.9986\n",
      "Epoch 30/30\n",
      "207637/207637 [==============================] - 7s 34us/step - loss: 0.0966 - acc: 0.9657 - val_loss: 0.0412 - val_acc: 0.9987\n",
      "Train on 227395 samples, validate on 25267 samples\n",
      "Epoch 1/30\n",
      "227395/227395 [==============================] - 8s 34us/step - loss: 0.1170 - acc: 0.9601 - val_loss: 0.0515 - val_acc: 0.9992\n",
      "Epoch 2/30\n",
      "227395/227395 [==============================] - 8s 34us/step - loss: 0.0891 - acc: 0.9731 - val_loss: 0.0378 - val_acc: 1.0000\n",
      "Epoch 3/30\n",
      "227395/227395 [==============================] - 8s 35us/step - loss: 0.0770 - acc: 0.9773 - val_loss: 0.0368 - val_acc: 1.0000\n",
      "Epoch 4/30\n",
      "227395/227395 [==============================] - 8s 34us/step - loss: 0.0692 - acc: 0.9796 - val_loss: 0.0290 - val_acc: 1.0000\n",
      "Epoch 5/30\n",
      "227395/227395 [==============================] - 8s 34us/step - loss: 0.0632 - acc: 0.9816 - val_loss: 0.0281 - val_acc: 1.0000\n",
      "Epoch 6/30\n",
      "227395/227395 [==============================] - 8s 34us/step - loss: 0.0583 - acc: 0.9828 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 7/30\n",
      "227395/227395 [==============================] - 8s 34us/step - loss: 0.0549 - acc: 0.9837 - val_loss: 0.0227 - val_acc: 1.0000\n",
      "Epoch 8/30\n",
      "227395/227395 [==============================] - 8s 34us/step - loss: 0.0514 - acc: 0.9848 - val_loss: 0.0232 - val_acc: 1.0000\n",
      "Epoch 9/30\n",
      "227395/227395 [==============================] - 8s 34us/step - loss: 0.0490 - acc: 0.9854 - val_loss: 0.0206 - val_acc: 1.0000\n",
      "Epoch 10/30\n",
      "227395/227395 [==============================] - 8s 34us/step - loss: 0.0469 - acc: 0.9858 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 11/30\n",
      "227395/227395 [==============================] - 8s 34us/step - loss: 0.0450 - acc: 0.9863 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "Epoch 12/30\n",
      "227395/227395 [==============================] - 8s 35us/step - loss: 0.0434 - acc: 0.9865 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 13/30\n",
      "227395/227395 [==============================] - 8s 35us/step - loss: 0.0414 - acc: 0.9871 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 14/30\n",
      "227395/227395 [==============================] - 8s 33us/step - loss: 0.0399 - acc: 0.9877 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 15/30\n",
      "227395/227395 [==============================] - 8s 33us/step - loss: 0.0390 - acc: 0.9878 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "Epoch 16/30\n",
      "227395/227395 [==============================] - 8s 33us/step - loss: 0.0375 - acc: 0.9883 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 17/30\n",
      "227395/227395 [==============================] - 8s 33us/step - loss: 0.0371 - acc: 0.9880 - val_loss: 0.0164 - val_acc: 1.0000\n",
      "Epoch 18/30\n",
      "227395/227395 [==============================] - 8s 33us/step - loss: 0.0362 - acc: 0.9886 - val_loss: 0.0166 - val_acc: 1.0000\n",
      "Epoch 19/30\n",
      "227395/227395 [==============================] - 8s 33us/step - loss: 0.0355 - acc: 0.9885 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "Epoch 20/30\n",
      "227395/227395 [==============================] - 8s 33us/step - loss: 0.0348 - acc: 0.9887 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "227395/227395 [==============================] - 8s 33us/step - loss: 0.0338 - acc: 0.9890 - val_loss: 0.0166 - val_acc: 1.0000\n",
      "Epoch 22/30\n",
      "227395/227395 [==============================] - 8s 33us/step - loss: 0.0334 - acc: 0.9892 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "227395/227395 [==============================] - 8s 33us/step - loss: 0.0327 - acc: 0.9892 - val_loss: 0.0133 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "227395/227395 [==============================] - 8s 33us/step - loss: 0.0328 - acc: 0.9891 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "227395/227395 [==============================] - 8s 34us/step - loss: 0.0318 - acc: 0.9895 - val_loss: 0.0156 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "227395/227395 [==============================] - 8s 34us/step - loss: 0.0316 - acc: 0.9892 - val_loss: 0.0149 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "227395/227395 [==============================] - 8s 34us/step - loss: 0.0310 - acc: 0.9897 - val_loss: 0.0136 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "227395/227395 [==============================] - 8s 33us/step - loss: 0.0307 - acc: 0.9897 - val_loss: 0.0140 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "227395/227395 [==============================] - 7s 32us/step - loss: 0.0303 - acc: 0.9897 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "227395/227395 [==============================] - 7s 32us/step - loss: 0.0298 - acc: 0.9897 - val_loss: 0.0150 - val_acc: 1.0000\n",
      "Train on 217483 samples, validate on 24165 samples\n",
      "Epoch 1/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.3164 - acc: 0.8821 - val_loss: 0.1510 - val_acc: 0.9588\n",
      "Epoch 2/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.1693 - acc: 0.9311 - val_loss: 0.0908 - val_acc: 0.9873\n",
      "Epoch 3/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.1237 - acc: 0.9510 - val_loss: 0.0640 - val_acc: 0.9969\n",
      "Epoch 4/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0993 - acc: 0.9617 - val_loss: 0.0426 - val_acc: 0.9993\n",
      "Epoch 5/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0827 - acc: 0.9689 - val_loss: 0.0413 - val_acc: 0.9995\n",
      "Epoch 6/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0735 - acc: 0.9726 - val_loss: 0.0382 - val_acc: 0.9998\n",
      "Epoch 7/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0666 - acc: 0.9758 - val_loss: 0.0294 - val_acc: 0.9998\n",
      "Epoch 8/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0611 - acc: 0.9780 - val_loss: 0.0281 - val_acc: 0.9999\n",
      "Epoch 9/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0575 - acc: 0.9791 - val_loss: 0.0295 - val_acc: 0.9992\n",
      "Epoch 10/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0530 - acc: 0.9806 - val_loss: 0.0297 - val_acc: 0.9997\n",
      "Epoch 11/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0498 - acc: 0.9816 - val_loss: 0.0252 - val_acc: 0.9998\n",
      "Epoch 12/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0475 - acc: 0.9824 - val_loss: 0.0224 - val_acc: 0.9998\n",
      "Epoch 13/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0454 - acc: 0.9831 - val_loss: 0.0196 - val_acc: 0.9999\n",
      "Epoch 14/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0446 - acc: 0.9833 - val_loss: 0.0246 - val_acc: 0.9999\n",
      "Epoch 15/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0431 - acc: 0.9835 - val_loss: 0.0208 - val_acc: 0.9999\n",
      "Epoch 16/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0419 - acc: 0.9843 - val_loss: 0.0227 - val_acc: 0.9999\n",
      "Epoch 17/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0402 - acc: 0.9846 - val_loss: 0.0213 - val_acc: 0.9997\n",
      "Epoch 18/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0396 - acc: 0.9846 - val_loss: 0.0216 - val_acc: 0.9996\n",
      "Epoch 19/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0381 - acc: 0.9851 - val_loss: 0.0214 - val_acc: 0.9999\n",
      "Epoch 20/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0377 - acc: 0.9854 - val_loss: 0.0190 - val_acc: 0.9999\n",
      "Epoch 21/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0360 - acc: 0.9858 - val_loss: 0.0203 - val_acc: 0.9999\n",
      "Epoch 22/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0359 - acc: 0.9857 - val_loss: 0.0200 - val_acc: 0.9997\n",
      "Epoch 23/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0356 - acc: 0.9859 - val_loss: 0.0177 - val_acc: 0.9999\n",
      "Epoch 24/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0349 - acc: 0.9862 - val_loss: 0.0190 - val_acc: 0.9999\n",
      "Epoch 25/30\n",
      "217483/217483 [==============================] - 7s 33us/step - loss: 0.0342 - acc: 0.9864 - val_loss: 0.0183 - val_acc: 0.9999\n",
      "Epoch 26/30\n",
      "217483/217483 [==============================] - 8s 35us/step - loss: 0.0334 - acc: 0.9865 - val_loss: 0.0156 - val_acc: 0.9999\n",
      "Epoch 27/30\n",
      "217483/217483 [==============================] - 8s 35us/step - loss: 0.0338 - acc: 0.9865 - val_loss: 0.0194 - val_acc: 0.9999\n",
      "Epoch 28/30\n",
      "217483/217483 [==============================] - 8s 37us/step - loss: 0.0333 - acc: 0.9867 - val_loss: 0.0162 - val_acc: 0.9999\n",
      "Epoch 29/30\n",
      "217483/217483 [==============================] - 8s 35us/step - loss: 0.0333 - acc: 0.9869 - val_loss: 0.0178 - val_acc: 0.9999\n",
      "Epoch 30/30\n",
      "217483/217483 [==============================] - 8s 35us/step - loss: 0.0321 - acc: 0.9870 - val_loss: 0.0178 - val_acc: 0.9999\n",
      "Train on 228994 samples, validate on 25444 samples\n",
      "Epoch 1/30\n",
      "228994/228994 [==============================] - 8s 35us/step - loss: 0.1747 - acc: 0.9472 - val_loss: 0.0505 - val_acc: 1.0000\n",
      "Epoch 2/30\n",
      "228994/228994 [==============================] - 8s 35us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0274 - val_acc: 0.9936\n",
      "Epoch 3/30\n",
      "228994/228994 [==============================] - 8s 34us/step - loss: 0.0501 - acc: 0.9846 - val_loss: 0.0119 - val_acc: 0.9936\n",
      "Epoch 4/30\n",
      "228994/228994 [==============================] - 7s 32us/step - loss: 0.0364 - acc: 0.9885 - val_loss: 0.0093 - val_acc: 0.9936\n",
      "Epoch 5/30\n",
      "228994/228994 [==============================] - 8s 36us/step - loss: 0.0295 - acc: 0.9907 - val_loss: 0.0115 - val_acc: 0.9936\n",
      "Epoch 6/30\n",
      "228994/228994 [==============================] - 8s 34us/step - loss: 0.0252 - acc: 0.9917 - val_loss: 0.0076 - val_acc: 0.9936\n",
      "Epoch 7/30\n",
      "228994/228994 [==============================] - 8s 35us/step - loss: 0.0224 - acc: 0.9924 - val_loss: 0.0072 - val_acc: 0.9936\n",
      "Epoch 8/30\n",
      "228994/228994 [==============================] - 8s 34us/step - loss: 0.0201 - acc: 0.9931 - val_loss: 0.0074 - val_acc: 0.9936\n",
      "Epoch 9/30\n",
      "228994/228994 [==============================] - 8s 34us/step - loss: 0.0192 - acc: 0.9933 - val_loss: 0.0079 - val_acc: 0.9936\n",
      "Epoch 10/30\n",
      "228994/228994 [==============================] - 8s 34us/step - loss: 0.0171 - acc: 0.9938 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 11/30\n",
      "228994/228994 [==============================] - 8s 33us/step - loss: 0.0171 - acc: 0.9937 - val_loss: 0.0068 - val_acc: 0.9936\n",
      "Epoch 12/30\n",
      "228994/228994 [==============================] - 9s 40us/step - loss: 0.0166 - acc: 0.9941 - val_loss: 0.0066 - val_acc: 0.9936\n",
      "Epoch 13/30\n",
      "228994/228994 [==============================] - 9s 38us/step - loss: 0.0154 - acc: 0.9944 - val_loss: 0.0079 - val_acc: 0.9936\n",
      "Epoch 14/30\n",
      "228994/228994 [==============================] - 8s 35us/step - loss: 0.0153 - acc: 0.9943 - val_loss: 0.0068 - val_acc: 0.9936\n",
      "Epoch 15/30\n",
      "228994/228994 [==============================] - 8s 36us/step - loss: 0.0152 - acc: 0.9943 - val_loss: 0.0065 - val_acc: 0.9936\n",
      "Epoch 16/30\n",
      "228994/228994 [==============================] - 8s 33us/step - loss: 0.0148 - acc: 0.9941 - val_loss: 0.0065 - val_acc: 0.9936\n",
      "Epoch 17/30\n",
      "228994/228994 [==============================] - 7s 33us/step - loss: 0.0142 - acc: 0.9947 - val_loss: 0.0085 - val_acc: 0.9936\n",
      "Epoch 18/30\n",
      "228994/228994 [==============================] - 8s 33us/step - loss: 0.0143 - acc: 0.9947 - val_loss: 0.0075 - val_acc: 0.9936\n",
      "Epoch 19/30\n",
      "228994/228994 [==============================] - 7s 32us/step - loss: 0.0139 - acc: 0.9947 - val_loss: 0.0068 - val_acc: 0.9936\n",
      "Epoch 20/30\n",
      "228994/228994 [==============================] - 7s 33us/step - loss: 0.0143 - acc: 0.9944 - val_loss: 0.0068 - val_acc: 0.9936\n",
      "Epoch 21/30\n",
      "228994/228994 [==============================] - 8s 35us/step - loss: 0.0140 - acc: 0.9946 - val_loss: 0.0068 - val_acc: 0.9936\n",
      "Epoch 22/30\n",
      "228994/228994 [==============================] - 8s 35us/step - loss: 0.0136 - acc: 0.9947 - val_loss: 0.0071 - val_acc: 0.9936\n",
      "Epoch 23/30\n",
      "228994/228994 [==============================] - 8s 37us/step - loss: 0.0134 - acc: 0.9948 - val_loss: 0.0072 - val_acc: 0.9936\n",
      "Epoch 24/30\n",
      "228994/228994 [==============================] - 8s 36us/step - loss: 0.0131 - acc: 0.9949 - val_loss: 0.0070 - val_acc: 0.9936\n",
      "Epoch 25/30\n",
      "228994/228994 [==============================] - 8s 35us/step - loss: 0.0133 - acc: 0.9947 - val_loss: 0.0070 - val_acc: 0.9936\n",
      "Epoch 26/30\n",
      "228994/228994 [==============================] - 8s 35us/step - loss: 0.0132 - acc: 0.9946 - val_loss: 0.0078 - val_acc: 0.9936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "228994/228994 [==============================] - 8s 33us/step - loss: 0.0134 - acc: 0.9946 - val_loss: 0.0067 - val_acc: 0.9936\n",
      "Epoch 28/30\n",
      "228994/228994 [==============================] - 8s 34us/step - loss: 0.0130 - acc: 0.9949 - val_loss: 0.0077 - val_acc: 0.9936\n",
      "Epoch 29/30\n",
      "228994/228994 [==============================] - 8s 34us/step - loss: 0.0128 - acc: 0.9949 - val_loss: 0.0075 - val_acc: 0.9936\n",
      "Epoch 30/30\n",
      "228994/228994 [==============================] - 8s 34us/step - loss: 0.0132 - acc: 0.9947 - val_loss: 0.0084 - val_acc: 0.9936\n",
      "Train on 218282 samples, validate on 24254 samples\n",
      "Epoch 1/30\n",
      "218282/218282 [==============================] - 8s 35us/step - loss: 0.4134 - acc: 0.8707 - val_loss: 0.1739 - val_acc: 0.9599\n",
      "Epoch 2/30\n",
      "218282/218282 [==============================] - 7s 34us/step - loss: 0.1992 - acc: 0.9228 - val_loss: 0.1128 - val_acc: 0.9791\n",
      "Epoch 3/30\n",
      "218282/218282 [==============================] - 7s 34us/step - loss: 0.1518 - acc: 0.9432 - val_loss: 0.0862 - val_acc: 0.9943\n",
      "Epoch 4/30\n",
      "218282/218282 [==============================] - 7s 34us/step - loss: 0.1248 - acc: 0.9549 - val_loss: 0.0658 - val_acc: 0.9989\n",
      "Epoch 5/30\n",
      "218282/218282 [==============================] - 7s 34us/step - loss: 0.1066 - acc: 0.9630 - val_loss: 0.0523 - val_acc: 0.9986\n",
      "Epoch 6/30\n",
      "218282/218282 [==============================] - 7s 34us/step - loss: 0.0935 - acc: 0.9684 - val_loss: 0.0454 - val_acc: 0.9995\n",
      "Epoch 7/30\n",
      "218282/218282 [==============================] - 7s 34us/step - loss: 0.0857 - acc: 0.9710 - val_loss: 0.0426 - val_acc: 0.9995\n",
      "Epoch 8/30\n",
      "218282/218282 [==============================] - 8s 34us/step - loss: 0.0783 - acc: 0.9741 - val_loss: 0.0354 - val_acc: 0.9995\n",
      "Epoch 9/30\n",
      "218282/218282 [==============================] - 7s 33us/step - loss: 0.0729 - acc: 0.9760 - val_loss: 0.0347 - val_acc: 0.9993\n",
      "Epoch 10/30\n",
      "218282/218282 [==============================] - 7s 34us/step - loss: 0.0685 - acc: 0.9773 - val_loss: 0.0331 - val_acc: 0.9995\n",
      "Epoch 11/30\n",
      "218282/218282 [==============================] - 7s 33us/step - loss: 0.0654 - acc: 0.9784 - val_loss: 0.0318 - val_acc: 0.9997\n",
      "Epoch 12/30\n",
      "218282/218282 [==============================] - 8s 36us/step - loss: 0.0622 - acc: 0.9795 - val_loss: 0.0293 - val_acc: 0.9995\n",
      "Epoch 13/30\n",
      "218282/218282 [==============================] - 7s 33us/step - loss: 0.0600 - acc: 0.9801 - val_loss: 0.0317 - val_acc: 0.9995\n",
      "Epoch 14/30\n",
      "218282/218282 [==============================] - 7s 33us/step - loss: 0.0573 - acc: 0.9810 - val_loss: 0.0306 - val_acc: 0.9993\n",
      "Epoch 15/30\n",
      "218282/218282 [==============================] - 7s 34us/step - loss: 0.0551 - acc: 0.9816 - val_loss: 0.0279 - val_acc: 0.9995\n",
      "Epoch 16/30\n",
      "218282/218282 [==============================] - 7s 33us/step - loss: 0.0541 - acc: 0.9823 - val_loss: 0.0301 - val_acc: 0.9997\n",
      "Epoch 17/30\n",
      "218282/218282 [==============================] - 8s 35us/step - loss: 0.0523 - acc: 0.9824 - val_loss: 0.0287 - val_acc: 0.9997\n",
      "Epoch 18/30\n",
      "218282/218282 [==============================] - 7s 34us/step - loss: 0.0515 - acc: 0.9829 - val_loss: 0.0255 - val_acc: 0.9997\n",
      "Epoch 19/30\n",
      "218282/218282 [==============================] - 7s 34us/step - loss: 0.0510 - acc: 0.9832 - val_loss: 0.0251 - val_acc: 0.9997\n",
      "Epoch 20/30\n",
      "218282/218282 [==============================] - 7s 34us/step - loss: 0.0487 - acc: 0.9838 - val_loss: 0.0280 - val_acc: 0.9997\n",
      "Epoch 21/30\n",
      "218282/218282 [==============================] - 8s 35us/step - loss: 0.0482 - acc: 0.9838 - val_loss: 0.0264 - val_acc: 0.9997\n",
      "Epoch 22/30\n",
      "218282/218282 [==============================] - 7s 34us/step - loss: 0.0471 - acc: 0.9842 - val_loss: 0.0262 - val_acc: 0.9993\n",
      "Epoch 23/30\n",
      "218282/218282 [==============================] - 8s 35us/step - loss: 0.0469 - acc: 0.9843 - val_loss: 0.0259 - val_acc: 0.9993\n",
      "Epoch 24/30\n",
      "218282/218282 [==============================] - 8s 37us/step - loss: 0.0450 - acc: 0.9846 - val_loss: 0.0228 - val_acc: 0.9995\n",
      "Epoch 25/30\n",
      "218282/218282 [==============================] - 8s 37us/step - loss: 0.0444 - acc: 0.9848 - val_loss: 0.0251 - val_acc: 0.9997\n",
      "Epoch 26/30\n",
      "218282/218282 [==============================] - 8s 37us/step - loss: 0.0448 - acc: 0.9847 - val_loss: 0.0256 - val_acc: 0.9995\n",
      "Epoch 27/30\n",
      "218282/218282 [==============================] - 8s 36us/step - loss: 0.0431 - acc: 0.9854 - val_loss: 0.0267 - val_acc: 0.9997\n",
      "Epoch 28/30\n",
      "218282/218282 [==============================] - 8s 36us/step - loss: 0.0435 - acc: 0.9852 - val_loss: 0.0264 - val_acc: 0.9997\n",
      "Epoch 29/30\n",
      "218282/218282 [==============================] - 8s 37us/step - loss: 0.0425 - acc: 0.9852 - val_loss: 0.0251 - val_acc: 0.9995\n",
      "Epoch 30/30\n",
      "139136/218282 [==================>...........] - ETA: 2s - loss: 0.0409 - acc: 0.9859"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    x_train_tfidf = x_train_tfidf_os_all[i]\n",
    "    x_train_tfidf = x_train_tfidf.toarray().reshape(x_train_tfidf.shape[0], 1, x_train_tfidf.shape[1])\n",
    "    history = model.fit(x_train_tfidf, y_train_tfidf_os_all[i],\n",
    "              batch_size=128, epochs=30,\n",
    "              verbose=1,\n",
    "              validation_split=0.1)\n",
    "    model.save('my_model' + str(i) +'.h5')\n",
    "    prediction_test.append(model.predict_proba(x_test_tfidf))\n",
    "    prediction_submission.append(model.predict_proba(x_submission_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_submission_array = np.asarray(prediction_submission).reshape(6, 153164).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_submission_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction_submission_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data=prediction_submission_array,columns=['toxic','severe_toxic','obscene','threat','insult','identity_hate'], index=toxic_test['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_1501.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[roc_auc_score(y_test.iloc[:,i], prediction_test[i]) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([roc_auc_score(y_test.iloc[:,i], prediction_test[i]) for i in range(6)]) / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.iloc[:,0], prediction_test[0] > 0.92))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
