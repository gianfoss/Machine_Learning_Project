{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install requirements & import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "l9-0OH4Vz5w7",
    "outputId": "240fa643-35ec-4ca4-a126-efb74e11f74f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.5/dist-packages (0.4.3)\r\n",
      "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.5/dist-packages (from imbalanced-learn) (1.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.5/dist-packages (from imbalanced-learn) (1.15.4)\r\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.5/dist-packages (from imbalanced-learn) (0.20.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "0zq26a83z5w-",
    "outputId": "cf6be28c-b36b-4181-b114-37e6d64b059c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.5/dist-packages (2.2.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras) (3.13)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.5/dist-packages (from keras) (1.0.5)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras) (1.15.4)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.5/dist-packages (from keras) (1.0.6)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:08:32.584649Z",
     "start_time": "2018-11-10T21:08:25.856600Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Y1LX4wIf40NN",
    "outputId": "73693c8c-2202-4fec-e4e6-f564af292b15",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2cv88aWPz5xF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, LSTM, Embedding, Input, GlobalMaxPool1D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2odG7o7L1_vY"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATdBNWcwz5xH"
   },
   "outputs": [],
   "source": [
    "toxic = pd.read_csv('train_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "colab_type": "code",
    "id": "hwSsYwTtz5xN",
    "outputId": "4aecf0ad-985e-417e-9578-fe7f02f66ead"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>comment_text_tokenize</th>\n",
       "      <th>comment_text_tokenize_stemmed</th>\n",
       "      <th>comment_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>159571</td>\n",
       "      <td>159305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158250</td>\n",
       "      <td>158225</td>\n",
       "      <td>157648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>a711da4623cebf13</td>\n",
       "      <td>jun       utc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['january']</td>\n",
       "      <td>['januari']</td>\n",
       "      <td>januari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id              comment_text          toxic  \\\n",
       "count             159571                    159571  159571.000000   \n",
       "unique            159571                    159305            NaN   \n",
       "top     a711da4623cebf13            jun       utc             NaN   \n",
       "freq                   1                        11            NaN   \n",
       "mean                 NaN                       NaN       0.095844   \n",
       "std                  NaN                       NaN       0.294379   \n",
       "min                  NaN                       NaN       0.000000   \n",
       "25%                  NaN                       NaN       0.000000   \n",
       "50%                  NaN                       NaN       0.000000   \n",
       "75%                  NaN                       NaN       0.000000   \n",
       "max                  NaN                       NaN       1.000000   \n",
       "\n",
       "         severe_toxic        obscene         threat         insult  \\\n",
       "count   159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "unique            NaN            NaN            NaN            NaN   \n",
       "top               NaN            NaN            NaN            NaN   \n",
       "freq              NaN            NaN            NaN            NaN   \n",
       "mean         0.009996       0.052948       0.002996       0.049364   \n",
       "std          0.099477       0.223931       0.054650       0.216627   \n",
       "min          0.000000       0.000000       0.000000       0.000000   \n",
       "25%          0.000000       0.000000       0.000000       0.000000   \n",
       "50%          0.000000       0.000000       0.000000       0.000000   \n",
       "75%          0.000000       0.000000       0.000000       0.000000   \n",
       "max          1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "        identity_hate comment_text_tokenize comment_text_tokenize_stemmed  \\\n",
       "count   159571.000000                159571                        159571   \n",
       "unique            NaN                158250                        158225   \n",
       "top               NaN           ['january']                   ['januari']   \n",
       "freq              NaN                    21                            21   \n",
       "mean         0.008805                   NaN                           NaN   \n",
       "std          0.093420                   NaN                           NaN   \n",
       "min          0.000000                   NaN                           NaN   \n",
       "25%          0.000000                   NaN                           NaN   \n",
       "50%          0.000000                   NaN                           NaN   \n",
       "75%          0.000000                   NaN                           NaN   \n",
       "max          1.000000                   NaN                           NaN   \n",
       "\n",
       "       comment_text_clean  \n",
       "count              159521  \n",
       "unique             157648  \n",
       "top               januari  \n",
       "freq                   22  \n",
       "mean                  NaN  \n",
       "std                   NaN  \n",
       "min                   NaN  \n",
       "25%                   NaN  \n",
       "50%                   NaN  \n",
       "75%                   NaN  \n",
       "max                   NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fXqX-dNwz5xM"
   },
   "source": [
    "#### Drop NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qV3R-Pr5z5xR"
   },
   "outputs": [],
   "source": [
    "toxic.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MKUN56Akz5xT"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(toxic.loc[:,'comment_text_clean'], toxic.iloc[:,2:8], test_size = .3, random_state = 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create word corpus (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZN_vJx0z5xX"
   },
   "outputs": [],
   "source": [
    "max_features = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCQ7cZxAz5xZ"
   },
   "outputs": [],
   "source": [
    "#TF-IDF Vectors as features\n",
    "\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=max_features)\n",
    "tfidf_vect.fit(x_train)\n",
    "x_train_tfidf =  tfidf_vect.transform(x_train)\n",
    "x_test_tfidf =  tfidf_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cgpWmbrTz5xf"
   },
   "outputs": [],
   "source": [
    "x_train_tfidf_os_all = []\n",
    "y_train_tfidf_os_all = []\n",
    "\n",
    "\n",
    "for i in range(6):   \n",
    "    sm_tfidf = RandomOverSampler(random_state=40)\n",
    "    x_train_tfidf_os, y_train_tfidf_os = sm_tfidf.fit_resample(x_train_tfidf, y_train.iloc[:,i])\n",
    "    x_train_tfidf_os_all.append(x_train_tfidf_os)\n",
    "    y_train_tfidf_os_all.append(y_train_tfidf_os)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BAfcmTZ7z5xi"
   },
   "source": [
    "### Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:33:59.787915Z",
     "start_time": "2018-11-10T21:33:59.578615Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "fd0AQ7adz5xj"
   },
   "outputs": [],
   "source": [
    "data_dim = max_features\n",
    "timesteps = 1\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(timesteps, data_dim), return_sequences=True))\n",
    "  \n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten()) \n",
    "\n",
    "model.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.0022)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.0022)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.0022)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.0022)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:34:08.703288Z",
     "start_time": "2018-11-10T21:34:08.616422Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "6nmaoxGDz5xm"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:34:03.251014Z",
     "start_time": "2018-11-10T21:34:03.237220Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "iL0A4YqSz5xn",
    "outputId": "bb66aa3f-2f04-4ad6-c167-d2618dde6937",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 64)             528640    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 545,345\n",
      "Trainable params: 545,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TLz72MMCz5xp"
   },
   "outputs": [],
   "source": [
    "prediction_train = []\n",
    "prediction_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A440nSi1z5xr"
   },
   "outputs": [],
   "source": [
    "x_test_tfidf = x_test_tfidf.toarray().reshape(x_test_tfidf.shape[0], 1, x_test_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:47:44.232376Z",
     "start_time": "2018-11-10T21:39:44.257993Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 897
    },
    "colab_type": "code",
    "id": "3GoDv9Nlz5xv",
    "outputId": "874a57f1-2f2a-481d-ef64-cc469e4f7d50",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 181528 samples, validate on 20170 samples\n",
      "Epoch 1/50\n",
      "181528/181528 [==============================] - 10s 54us/step - loss: 0.3830 - acc: 0.8602 - val_loss: 0.2889 - val_acc: 0.9062\n",
      "Epoch 2/50\n",
      "181528/181528 [==============================] - 8s 46us/step - loss: 0.2681 - acc: 0.9079 - val_loss: 0.2746 - val_acc: 0.8909\n",
      "Epoch 3/50\n",
      "181528/181528 [==============================] - 8s 46us/step - loss: 0.2499 - acc: 0.9128 - val_loss: 0.2171 - val_acc: 0.9121\n",
      "Epoch 4/50\n",
      "181528/181528 [==============================] - 8s 47us/step - loss: 0.2379 - acc: 0.9159 - val_loss: 0.2261 - val_acc: 0.9141\n",
      "Epoch 5/50\n",
      "181528/181528 [==============================] - 8s 47us/step - loss: 0.2288 - acc: 0.9188 - val_loss: 0.2512 - val_acc: 0.8990\n",
      "Train on 198966 samples, validate on 22108 samples\n",
      "Epoch 1/50\n",
      "198966/198966 [==============================] - 9s 47us/step - loss: 0.1388 - acc: 0.9661 - val_loss: 0.0844 - val_acc: 0.9953\n",
      "Epoch 2/50\n",
      "198966/198966 [==============================] - 9s 46us/step - loss: 0.1047 - acc: 0.9793 - val_loss: 0.0692 - val_acc: 0.9962\n",
      "Epoch 3/50\n",
      "198966/198966 [==============================] - 9s 46us/step - loss: 0.0938 - acc: 0.9826 - val_loss: 0.0555 - val_acc: 0.9962\n",
      "Epoch 4/50\n",
      "198966/198966 [==============================] - 9s 47us/step - loss: 0.0866 - acc: 0.9842 - val_loss: 0.0562 - val_acc: 0.9962\n",
      "Epoch 5/50\n",
      "198966/198966 [==============================] - 10s 48us/step - loss: 0.0831 - acc: 0.9852 - val_loss: 0.0646 - val_acc: 0.9962\n",
      "Train on 190200 samples, validate on 21134 samples\n",
      "Epoch 1/50\n",
      "190200/190200 [==============================] - 9s 47us/step - loss: 0.1936 - acc: 0.9371 - val_loss: 0.1654 - val_acc: 0.9460\n",
      "Epoch 2/50\n",
      "190200/190200 [==============================] - 9s 47us/step - loss: 0.1469 - acc: 0.9517 - val_loss: 0.1221 - val_acc: 0.9540\n",
      "Epoch 3/50\n",
      "190200/190200 [==============================] - 9s 47us/step - loss: 0.1346 - acc: 0.9556 - val_loss: 0.1133 - val_acc: 0.9565\n",
      "Epoch 4/50\n",
      "190200/190200 [==============================] - 9s 47us/step - loss: 0.1285 - acc: 0.9578 - val_loss: 0.1016 - val_acc: 0.9585\n",
      "Epoch 5/50\n",
      "190200/190200 [==============================] - 9s 47us/step - loss: 0.1232 - acc: 0.9600 - val_loss: 0.0770 - val_acc: 0.9894\n",
      "Epoch 6/50\n",
      "190200/190200 [==============================] - 9s 47us/step - loss: 0.1193 - acc: 0.9612 - val_loss: 0.0796 - val_acc: 0.9878\n",
      "Epoch 7/50\n",
      "190200/190200 [==============================] - 9s 47us/step - loss: 0.1159 - acc: 0.9630 - val_loss: 0.0894 - val_acc: 0.9642\n",
      "Train on 200365 samples, validate on 22263 samples\n",
      "Epoch 1/50\n",
      "200365/200365 [==============================] - 10s 48us/step - loss: 0.1366 - acc: 0.9638 - val_loss: 0.0561 - val_acc: 0.9944\n",
      "Epoch 2/50\n",
      "200365/200365 [==============================] - 9s 47us/step - loss: 0.0751 - acc: 0.9854 - val_loss: 0.0519 - val_acc: 0.9944\n",
      "Epoch 3/50\n",
      "200365/200365 [==============================] - 10s 49us/step - loss: 0.0588 - acc: 0.9900 - val_loss: 0.0378 - val_acc: 0.9944\n",
      "Epoch 4/50\n",
      "200365/200365 [==============================] - 10s 48us/step - loss: 0.0514 - acc: 0.9920 - val_loss: 0.0385 - val_acc: 0.9944\n",
      "Epoch 5/50\n",
      "200365/200365 [==============================] - 10s 48us/step - loss: 0.0463 - acc: 0.9928 - val_loss: 0.0371 - val_acc: 0.9944\n",
      "Epoch 6/50\n",
      "200365/200365 [==============================] - 10s 49us/step - loss: 0.0425 - acc: 0.9933 - val_loss: 0.0300 - val_acc: 0.9944\n",
      "Epoch 7/50\n",
      "200365/200365 [==============================] - 10s 48us/step - loss: 0.0404 - acc: 0.9935 - val_loss: 0.0309 - val_acc: 0.9944\n",
      "Epoch 8/50\n",
      "200365/200365 [==============================] - 10s 48us/step - loss: 0.0387 - acc: 0.9937 - val_loss: 0.0307 - val_acc: 0.9944\n",
      "Train on 190908 samples, validate on 21212 samples\n",
      "Epoch 1/50\n",
      "190908/190908 [==============================] - 9s 48us/step - loss: 0.2558 - acc: 0.9124 - val_loss: 0.1862 - val_acc: 0.9439\n",
      "Epoch 2/50\n",
      "190908/190908 [==============================] - 9s 48us/step - loss: 0.1913 - acc: 0.9345 - val_loss: 0.1361 - val_acc: 0.9705\n",
      "Epoch 3/50\n",
      "190908/190908 [==============================] - 9s 47us/step - loss: 0.1726 - acc: 0.9405 - val_loss: 0.1133 - val_acc: 0.9875\n",
      "Epoch 4/50\n",
      "190908/190908 [==============================] - 9s 48us/step - loss: 0.1626 - acc: 0.9443 - val_loss: 0.1310 - val_acc: 0.9432\n",
      "Epoch 5/50\n",
      "190908/190908 [==============================] - 9s 48us/step - loss: 0.1559 - acc: 0.9477 - val_loss: 0.1084 - val_acc: 0.9788\n",
      "Epoch 6/50\n",
      "190908/190908 [==============================] - 9s 47us/step - loss: 0.1506 - acc: 0.9500 - val_loss: 0.1041 - val_acc: 0.9902\n",
      "Epoch 7/50\n",
      "190908/190908 [==============================] - 9s 47us/step - loss: 0.1476 - acc: 0.9516 - val_loss: 0.1111 - val_acc: 0.9919\n",
      "Epoch 8/50\n",
      "190908/190908 [==============================] - 9s 47us/step - loss: 0.1432 - acc: 0.9538 - val_loss: 0.0842 - val_acc: 0.9976\n",
      "Epoch 9/50\n",
      "190908/190908 [==============================] - 9s 47us/step - loss: 0.1394 - acc: 0.9556 - val_loss: 0.0987 - val_acc: 0.9956\n",
      "Epoch 10/50\n",
      "190908/190908 [==============================] - 9s 47us/step - loss: 0.1361 - acc: 0.9571 - val_loss: 0.0674 - val_acc: 0.9983\n",
      "Epoch 11/50\n",
      "190908/190908 [==============================] - 9s 47us/step - loss: 0.1317 - acc: 0.9593 - val_loss: 0.0866 - val_acc: 0.9969\n",
      "Epoch 12/50\n",
      "190908/190908 [==============================] - 9s 47us/step - loss: 0.1293 - acc: 0.9602 - val_loss: 0.0902 - val_acc: 0.9904\n",
      "Train on 199188 samples, validate on 22132 samples\n",
      "Epoch 1/50\n",
      "199188/199188 [==============================] - 9s 48us/step - loss: 0.1688 - acc: 0.9506 - val_loss: 0.0587 - val_acc: 0.9964\n",
      "Epoch 2/50\n",
      "199188/199188 [==============================] - 9s 47us/step - loss: 0.1089 - acc: 0.9717 - val_loss: 0.0511 - val_acc: 0.9964\n",
      "Epoch 3/50\n",
      "199188/199188 [==============================] - 9s 47us/step - loss: 0.0926 - acc: 0.9775 - val_loss: 0.0549 - val_acc: 0.9964\n",
      "Epoch 4/50\n",
      "199188/199188 [==============================] - 9s 47us/step - loss: 0.0834 - acc: 0.9808 - val_loss: 0.0405 - val_acc: 0.9971\n",
      "Epoch 5/50\n",
      "199188/199188 [==============================] - 9s 48us/step - loss: 0.0768 - acc: 0.9826 - val_loss: 0.0479 - val_acc: 0.9958\n",
      "Epoch 6/50\n",
      "199188/199188 [==============================] - 9s 47us/step - loss: 0.0720 - acc: 0.9845 - val_loss: 0.0438 - val_acc: 0.9958\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n",
    "             ModelCheckpoint(filepath='best_model' + str(i) +'1500.h5', monitor='val_loss', save_best_only=True)]\n",
    "    \n",
    "    x_train_tfidf_os = x_train_tfidf_os_all[i]\n",
    "    x_train_tfidf_os = x_train_tfidf_os.toarray().reshape(x_train_tfidf_os.shape[0], 1, x_train_tfidf_os.shape[1])\n",
    "    history = model.fit(x_train_tfidf_os, y_train_tfidf_os_all[i],\n",
    "              batch_size=128, epochs=50, callbacks=callbacks,\n",
    "              verbose=1,\n",
    "              validation_split=0.1)\n",
    "    model.save('my_model' + str(i) +'1500.h5')\n",
    "    prediction_train.append(model.predict_proba(x_train_tfidf.toarray().reshape(x_train_tfidf.shape[0], 1, x_train_tfidf.shape[1])))\n",
    "    prediction_test.append(model.predict_proba(x_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4XaKamnNz5x2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction_submission_array = np.asarray(prediction_test).reshape(6, 47857).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MzTs0QKKz5x4"
   },
   "outputs": [],
   "source": [
    "proba = pd.DataFrame(data=prediction_submission_array,columns=['toxic','severe_toxic','obscene','threat','insult','identity_hate'], index=x_test.index.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nPxAj9K7z5x6"
   },
   "outputs": [],
   "source": [
    "proba.to_csv('submission_1500_max_feature.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "KgJP7z3Lz5x7",
    "outputId": "4d1060c5-6a74-43a5-8e4a-44c40bcf787c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "f1_train = []\n",
    "cutoff = []\n",
    "for i in range(6):\n",
    "    best_f1 = 0\n",
    "    best_val = 0\n",
    "    for val in np.arange(0,1,0.01):\n",
    "        if f1_score(y_train.iloc[:,i], prediction_train[i] > val) > best_f1:\n",
    "            best_f1 = f1_score(y_train.iloc[:,i], prediction_train[i] > val)\n",
    "            best_val = val\n",
    "    f1_train.append(best_f1)\n",
    "    cutoff.append(best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "-Qra_kPzz5x-",
    "outputId": "e160ddf2-95db-490b-c08e-759968e59684",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7883842794759826,\n",
       " 0.5341074020319303,\n",
       " 0.8575015693659762,\n",
       " 0.7604395604395605,\n",
       " 0.7984862819299906,\n",
       " 0.6981059141863161]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_gp6uWQ3z5yC",
    "outputId": "24c8fbc1-09ea-4184-9bb4-c481f63d8f5a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.75, 0.9400000000000001, 0.89, 0.99, 0.88, 0.97]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "bsp9H1FQz5yF",
    "outputId": "f4619bcc-c754-4e9b-c2cb-fffa3d08abf3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1_test = [f1_score(y_test.iloc[:,i] , prediction_test[i] > cutoff[i]) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7284487329021312,\n",
       " 0.4233750745378652,\n",
       " 0.782760629004077,\n",
       " 0.364741641337386,\n",
       " 0.6867804684398571,\n",
       " 0.4819027921406412]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mshzyR1z5yH"
   },
   "outputs": [],
   "source": [
    "roc_auc_train = [roc_auc_score(y_train.iloc[:,i], prediction_train[i]) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfQ8Wjm8z5yJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc_auc_test = [roc_auc_score(y_test.iloc[:,i], prediction_test[i]) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "SrSJE3FEz5yL",
    "outputId": "9c193a15-c32d-4231-c0fc-917dea2b5a9f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9796124889516942,\n",
       " 0.9920669643080401,\n",
       " 0.995367522499929,\n",
       " 0.9992089558751435,\n",
       " 0.9920307539414144,\n",
       " 0.9971161756372305]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "m7LIiogez5yM",
    "outputId": "f33c402c-b32b-42b5-c652-4ccc73b62c8b",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9497496068532831,\n",
       " 0.9723682675106001,\n",
       " 0.9711142629152563,\n",
       " 0.9440396889207819,\n",
       " 0.9596516371703349,\n",
       " 0.9489697662452096]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_test"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Toxic_Comment_Classification_Neural_Network_100.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
