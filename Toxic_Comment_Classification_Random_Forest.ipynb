{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.5/dist-packages (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.5/dist-packages (from imbalanced-learn) (1.15.4)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.5/dist-packages (from imbalanced-learn) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.5/dist-packages (from imbalanced-learn) (0.20.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "toxic = pd.read_csv('train_cleaned.csv')\n",
    "\n",
    "max_features = 1000\n",
    "\n",
    "toxic.dropna(axis=0, inplace=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(toxic.loc[:,'comment_text_clean'], toxic.iloc[:,2:8], test_size = .2, random_state = 43)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF Vectors as features\n",
    "\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=max_features)\n",
    "tfidf_vect.fit(x_train)\n",
    "x_train_tfidf =  tfidf_vect.transform(x_train)\n",
    "x_test_tfidf =  tfidf_vect.transform(x_test)\n",
    "\n",
    "x_train_tfidf_os_all = [] #os = oversample\n",
    "y_train_tfidf_os_all = []\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "   sm_tfidf = RandomOverSampler(random_state=40)\n",
    "   x_train_tfidf_os, y_train_tfidf_os = sm_tfidf.fit_resample(x_train_tfidf, y_train.iloc[:,i])\n",
    "   x_train_tfidf_os_all.append(x_train_tfidf_os)\n",
    "   y_train_tfidf_os_all.append(y_train_tfidf_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:  5.4min remaining:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  6.5min remaining:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  7.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:  4.8min remaining:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  5.7min remaining:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  6.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:  5.4min remaining:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  6.3min remaining:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  7.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:  3.9min remaining:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  4.6min remaining:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  5.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:  5.0min remaining:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  6.0min remaining:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  7.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:  4.7min remaining:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  5.5min remaining:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  6.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  6.5min finished\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6370630907891844, 0.5678496868475991, 0.678496067523499, 0.4520884520884521, 0.6562291169451074, 0.32875783765463484]\n",
      "[0.5783908045977012, 0.4494086727989488, 0.6071282261368292, 0.19230769230769232, 0.5842235004108463, 0.24128312412831243]\n",
      "[0.9031222119395219, 0.9669662921348315, 0.953550408555818, 0.9058527534153896, 0.9421733114143158, 0.9209279282469266]\n",
      "[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=None,\n",
      "            oob_score=False, random_state=64, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=None,\n",
      "            oob_score=False, random_state=64, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=None,\n",
      "            oob_score=False, random_state=64, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=None,\n",
      "            oob_score=False, random_state=64, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=None,\n",
      "            oob_score=False, random_state=64, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=None,\n",
      "            oob_score=False, random_state=64, verbose=0, warm_start=False)]\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "#Start building model here\n",
    "\n",
    "class toxicmodel:\n",
    "   def __init__(self, x_train, y_train, x_test, y_test, x_train_tfidf, n=6):\n",
    "       self.n = n\n",
    "       self.x_train = x_train\n",
    "       self.y_train = y_train\n",
    "       self.x_test = x_test\n",
    "       self.y_test = y_test\n",
    "       self.x_train_tfidf = x_train_tfidf\n",
    "\n",
    "       self.best_params = []\n",
    "       self.best_estimator = []\n",
    "\n",
    "       self.y_predict_train = []\n",
    "       self.y_predict_test = []\n",
    "       self.y_predict_proba_train = []\n",
    "       self.y_predict_proba_test = []\n",
    "\n",
    "       self.acc_score_train = []\n",
    "       self.acc_score_test = []\n",
    "\n",
    "       self.roc_auc_score_train = []\n",
    "       self.roc_auc_score_test = []\n",
    "\n",
    "       self.f1_score_train = []\n",
    "       self.f1_score_test = []\n",
    "\n",
    "       self.confusion_matrix_train = []\n",
    "       self.confusion_matrix_test = []\n",
    "\n",
    "       self.classification_report_train = []\n",
    "       self.classification_report_test = []\n",
    "\n",
    "\n",
    "   def trainmodel(self, model_name, hyper_param_grid):\n",
    "       for i in range(self.n):\n",
    "           grid_search_model = GridSearchCV(model_name, hyper_param_grid, scoring='roc_auc', cv=5, refit=True, n_jobs=-1,\n",
    "                                            # n_iter=10,\n",
    "                                            verbose=5)\n",
    "           grid_search_model.fit(self.x_train[i], self.y_train[i])\n",
    "           self.best_params.append(grid_search_model.best_params_)\n",
    "           self.best_estimator.append(grid_search_model.best_estimator_)\n",
    "\n",
    "   def predictmodel(self):\n",
    "       for i in range(self.n):\n",
    "           y_predict_train = self.best_estimator[i].predict(self.x_train_tfidf)\n",
    "           y_predict_test = self.best_estimator[i].predict(self.x_test)\n",
    "\n",
    "           y_predict_proba_train = self.best_estimator[i].predict_proba(self.x_train_tfidf)[:, 1]\n",
    "           y_predict_proba_test = self.best_estimator[i].predict_proba(self.x_test)[:, 1]\n",
    "\n",
    "           self.y_predict_train.append(y_predict_train)\n",
    "           self.y_predict_test.append(y_predict_test)\n",
    "\n",
    "           self.y_predict_proba_train.append(y_predict_proba_train)\n",
    "           self.y_predict_proba_test.append(y_predict_proba_test)\n",
    "\n",
    "           # self.roc_auc_score_train.append(roc_auc_score(self.y_train[i], y_predict_proba_train))\n",
    "           self.roc_auc_score_test.append(roc_auc_score(self.y_test.iloc[:, i], y_predict_proba_test))\n",
    "\n",
    "           # self.acc_score_train.append(accuracy_score(self.y_train[i], y_predict_train))\n",
    "           # self.acc_score_test.append(accuracy_score(self.y_test.iloc[:,i], y_predict_test))\n",
    "\n",
    "           # self.f1_score_train.append(f1_score(self.y_train[i], y_predict_train))\n",
    "           # self.f1_score_test.append(f1_score(self.y_test.iloc[:,i], y_predict_test))\n",
    "\n",
    "           # self.confusion_matrix_train.append(confusion_matrix(self.y_train[i], y_predict_train))\n",
    "           # self.confusion_matrix_test.append(confusion_matrix(self.y_test.iloc[:,i], y_predict_test))\n",
    "\n",
    "           # self.classification_report_train.append(classification_report(self.y_train[i], y_predict_train))\n",
    "           # self.classification_report_test.append(classification_report(self.y_test.iloc[:,i], y_predict_test))\n",
    "\n",
    "\n",
    "rf = toxicmodel(x_train_tfidf_os_all, y_train_tfidf_os_all, x_test_tfidf, y_test, x_train_tfidf, n=6)\n",
    "rf.trainmodel(RandomForestClassifier(), {'random_state': [64],\n",
    "                                         'n_estimators': [400,600],\n",
    "                                         'max_depth': [15]\n",
    "                                         })\n",
    "rf.predictmodel()\n",
    "\n",
    "train_f1 = []\n",
    "cutoff = []\n",
    "for i in range(6):\n",
    "    best_f1 = 0\n",
    "    best_cutoff = 0\n",
    "    for j in np.arange(0, 1, 0.001):\n",
    "        if f1_score(y_train.iloc[:, i], rf.y_predict_proba_train[i] > j) > best_cutoff:\n",
    "            best_f1 = f1_score(y_train.iloc[:, i], rf.y_predict_proba_train[i] > j)\n",
    "            best_cutoff = j\n",
    "    train_f1.append(best_f1)\n",
    "    cutoff.append(best_cutoff)\n",
    "\n",
    "test_f1 = [f1_score(y_test.iloc[:, i], rf.y_predict_proba_test[i] > cutoff[i]) for i in range(6)]\n",
    "print(train_f1)\n",
    "print(test_f1)\n",
    "print(rf.roc_auc_score_test)\n",
    "print(rf.best_estimator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
