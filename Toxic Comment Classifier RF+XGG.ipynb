{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "hvwTHgG3HeXI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a71dd07-6c32-47bf-8750-203eebcf6ea5"
      },
      "cell_type": "code",
      "source": [
        "#PARAMETERS\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "#Utility stuff\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "np.random.seed(235)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s4uSnkgDQbeV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#GLOBAL & CONSTANTS\n",
        "GOOGLE_DRIVE_CODE_DIR = '/content/gdrive/My Drive/Code/'\n",
        "SUBJECT_DIR = 'Machine Learning & Predictive Analytics/'\n",
        "PROCESSED_DATA_DIR = 'data/Processed/'\n",
        "MODEL_DIR = 'models/'\n",
        "LOGS_DIR = 'logs/'\n",
        "\n",
        "#NOTEBOOK SPECIFIC\n",
        "HOMEWORK_DIR = 'Project/'\n",
        "TRAIN_DATA = 'train_data_array.pkl'\n",
        "TEST_DATA = 'test_data_array.pkl'\n",
        "NOTEBOOK_NAME = 'Toxic Comment Classification.ipynb'\n",
        "\n",
        "\n",
        "MAIN_PATH = os.path.join(GOOGLE_DRIVE_CODE_DIR\n",
        "                    ,SUBJECT_DIR\n",
        "                    ,HOMEWORK_DIR\n",
        "                    )\n",
        "\n",
        "INPUT_DATA_PATH = os.path.join(MAIN_PATH\n",
        "                    ,PROCESSED_DATA_DIR\n",
        "                    )\n",
        "\n",
        "TEST_DATA = os.path.join(INPUT_DATA_PATH\n",
        "                    ,TEST_DATA\n",
        "                    )\n",
        "\n",
        "TRAIN_PATH = os.path.join(INPUT_DATA_PATH\n",
        "                    ,TRAIN_DATA\n",
        "                    )\n",
        "\n",
        "NOTEBOOK_FILE = os.path.join(MAIN_PATH\n",
        "                    ,NOTEBOOK_NAME)\n",
        "\n",
        "MODEL_EXPORT_PATH = os.path.join(MAIN_PATH\n",
        "                    ,MODEL_DIR)\n",
        "\n",
        "LOG_PATH = os.path.join(MAIN_PATH\n",
        "                    ,LOGS_DIR)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n3aTjytAQEBD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "x_train_y_train_all_load = pickle.load(open(TRAIN_PATH, 'rb'))\n",
        "x_test_y_test_all_load = pickle.load(open(TEST_DATA, 'rb'))\n",
        "\n",
        "x_train_cv_os_all = x_train_y_train_all_load[0]\n",
        "y_train_cv_os_all = x_train_y_train_all_load[1]\n",
        "\n",
        "x_train_tfidf_os_all = x_train_y_train_all_load[2]\n",
        "y_train_tfidf_os_all = x_train_y_train_all_load[3]\n",
        "\n",
        "x_test_cv = x_test_y_test_all_load[0]\n",
        "x_test_tfidf = x_test_y_test_all_load[2]\n",
        "y_test = x_test_y_test_all_load[1]\n",
        "\n",
        "y_test = [np.array(y_test.iloc[:,i]).reshape(-1,1) for i in range(6)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KiumePa7HfH-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class toxicmodel:\n",
        "    def __init__(self, x_train, y_train, x_test, y_test, n = 6):\n",
        "        self.n = n\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.x_test = x_test\n",
        "        self.y_test = y_test\n",
        "        \n",
        "        self.best_params = []\n",
        "        self.best_estimator = []\n",
        "        \n",
        "        self.y_predict_train = []\n",
        "        self.y_predict_test = []\n",
        "        self.y_predict_proba_train = []\n",
        "        self.y_predict_proba_test = []\n",
        "\n",
        "        self.acc_score_train = []\n",
        "        self.acc_score_test = []\n",
        "\n",
        "        self.roc_auc_score_train = []\n",
        "        self.roc_auc_score_test = []\n",
        "\n",
        "        self.f1_score_train = []\n",
        "        self.f1_score_test = []\n",
        "\n",
        "        self.confusion_matrix_train = []\n",
        "        self.confusion_matrix_test = []\n",
        "\n",
        "        self.classification_report_train = []\n",
        "        self.classification_report_test = []\n",
        "\n",
        "    \n",
        "    def trainmodel(self, model_name, hyper_param_grid):\n",
        "        for i in range(self.n):\n",
        "            grid_search_model = GridSearchCV(model_name, hyper_param_grid, scoring = 'f1', cv = 5,refit = True, n_jobs=-1, verbose = 5)\n",
        "            grid_search_model.fit(self.x_train[i], self.y_train[i])\n",
        "            self.best_params.append(grid_search_model.best_params_)\n",
        "            self.best_estimator.append(grid_search_model.best_estimator_)\n",
        "    \n",
        "    \n",
        "    def predictmodel(self):\n",
        "        for i in range(self.n):\n",
        "            \n",
        "            y_predict_train = self.best_estimator[i].predict(self.x_train[i])\n",
        "            y_predict_test = self.best_estimator[i].predict(self.x_test)\n",
        "             \n",
        "            #y_predict_proba_train = self.best_estimator[i].predict_proba(self.x_train[i])[:,1]\n",
        "            #y_predict_proba_test = self.best_estimator[i].predict_proba(self.x_test)[:,1]\n",
        "            \n",
        "\n",
        "            #self.y_predict_train.append(y_predict_train)\n",
        "            #self.y_predict_test.append(y_predict_test)\n",
        "            \n",
        "            #self.y_predict_proba_train.append(y_predict_proba_train)\n",
        "            #self.y_predict_proba_test.append(y_predict_proba_test)\n",
        "\n",
        "            #self.roc_auc_score_train.append(roc_auc_score(self.y_train[i], y_predict_proba_train))\n",
        "            #self.roc_auc_score_test.append(roc_auc_score(self.y_test[i], y_predict_proba_test))\n",
        "            \n",
        "            self.acc_score_train.append(accuracy_score(self.y_train[i], y_predict_train))\n",
        "            self.acc_score_test.append(accuracy_score(self.y_test[i], y_predict_test))\n",
        "            \n",
        "            self.f1_score_train.append(f1_score(self.y_train[i], y_predict_train))\n",
        "            self.f1_score_test.append(f1_score(self.y_test[i], y_predict_test))\n",
        "\n",
        "            self.confusion_matrix_train.append(confusion_matrix(self.y_train[i], y_predict_train))\n",
        "            self.confusion_matrix_test.append(confusion_matrix(self.y_test[i], y_predict_test))\n",
        "\n",
        "            self.classification_report_train.append(classification_report(self.y_train[i], y_predict_train))\n",
        "            self.classification_report_test.append(classification_report(self.y_test[i], y_predict_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lcY3_v0XPCSB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_estimators = []\n",
        "max_features = []\n",
        "max_depth = []\n",
        "\n",
        "n_estimators.append(np.arange(100, 200, 50))\n",
        "max_features.append(np.arange(1,5,1))\n",
        "max_depth.append(np.array([1]))\n",
        "\n",
        "n_estimators.append(np.arange(100, 200, 50))\n",
        "max_features.append(np.arange(1,5,1))\n",
        "max_depth.append(np.array([1]))\n",
        "\n",
        "rf_param_grid = {'n_estimators':n_estimators[0]\n",
        "                 ,'max_features':max_features[0]\n",
        "                 ,'max_depth':max_depth[0]\n",
        "                 ,'random_state':[235]\n",
        "                }\n",
        "\n",
        "xg_param_grid = {'objective':['binary:logistic']\n",
        "                 ,'n_estimators':n_estimators[1]\n",
        "                 ,'max_features':max_features[1]\n",
        "                 ,'max_depth':max_depth[1]\n",
        "                 ,'random_state':[235]\n",
        "                #,'learning_rate': [0.15], #so called `eta` value\n",
        "                #,'min_child_weight': [3,11],\n",
        "                #'colsample_bytree': [0.5],\n",
        "                }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H6EwUba-Jyub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "97cc688b-5bb5-47da-f3bc-dd3f41e58fb0"
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    RF_toxic = toxicmodel(x_train_tfidf_os_all, y_train_tfidf_os_all, x_test_tfidf, y_test)\n",
        "    RF_toxic.trainmodel(RandomForestClassifier(), rf_param_grid)\n",
        "    RF_toxic.predictmodel()\n",
        "\n",
        "    \n",
        "    RF_toxic_pkl_path = os.path.join(MAIN_PATH\n",
        "                                     ,MODEL_DIR\n",
        "                                     ,'RF_toxic_pkl_path')\n",
        "    RF_toxic_pkl = open(RF_toxic_pkl_path, 'wb')\n",
        "    pickle.dump(RF_toxic, RF_toxic_pkl)\n",
        "    \n",
        "    XGB_toxic = toxicmodel(x_train_tfidf_os_all, y_train_tfidf_os_all, x_test_tfidf, y_test)\n",
        "    XGB_toxic.trainmodel(XGBClassifier(), xg_param_grid)\n",
        "    XGB_toxic.predictmodel()\n",
        "\n",
        "    XGB_toxic_pkl_path = os.path.join(MAIN_PATH\n",
        "                                      ,MODEL_DIR\n",
        "                                      ,'XGB_toxic_pkl_path')\n",
        "    \n",
        "    XGB_toxic_pkl = open(XGB_toxic_pkl_path, 'wb')\n",
        "    pickle.dump(XGB_toxic, XGB_toxic_pkl)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   57.1s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   57.6s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "sWHhjirLRfG6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}