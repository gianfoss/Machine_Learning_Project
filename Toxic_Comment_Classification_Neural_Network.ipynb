{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install requirements & import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "l9-0OH4Vz5w7",
    "outputId": "240fa643-35ec-4ca4-a126-efb74e11f74f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.5/dist-packages (0.4.3)\r\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.5/dist-packages (from imbalanced-learn) (1.15.4)\r\n",
      "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.5/dist-packages (from imbalanced-learn) (1.1.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.5/dist-packages (from imbalanced-learn) (0.20.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "0zq26a83z5w-",
    "outputId": "cf6be28c-b36b-4181-b114-37e6d64b059c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.5/dist-packages (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras) (1.15.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.5/dist-packages (from keras) (1.0.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.5/dist-packages (from keras) (1.0.5)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras) (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:08:32.584649Z",
     "start_time": "2018-11-10T21:08:25.856600Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Y1LX4wIf40NN",
    "outputId": "73693c8c-2202-4fec-e4e6-f564af292b15",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2cv88aWPz5xF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, LSTM, Embedding, Input, GlobalMaxPool1D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2odG7o7L1_vY"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATdBNWcwz5xH"
   },
   "outputs": [],
   "source": [
    "toxic = pd.read_csv('train_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "colab_type": "code",
    "id": "hwSsYwTtz5xN",
    "outputId": "4aecf0ad-985e-417e-9578-fe7f02f66ead"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>comment_text_tokenize</th>\n",
       "      <th>comment_text_tokenize_stemmed</th>\n",
       "      <th>comment_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>159571</td>\n",
       "      <td>159305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158250</td>\n",
       "      <td>158225</td>\n",
       "      <td>157648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>90f77cb80a1f7f0e</td>\n",
       "      <td>jun       utc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['january']</td>\n",
       "      <td>['januari']</td>\n",
       "      <td>thank experi wikipedia test work revert remov ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id              comment_text          toxic  \\\n",
       "count             159571                    159571  159571.000000   \n",
       "unique            159571                    159305            NaN   \n",
       "top     90f77cb80a1f7f0e            jun       utc             NaN   \n",
       "freq                   1                        11            NaN   \n",
       "mean                 NaN                       NaN       0.095844   \n",
       "std                  NaN                       NaN       0.294379   \n",
       "min                  NaN                       NaN       0.000000   \n",
       "25%                  NaN                       NaN       0.000000   \n",
       "50%                  NaN                       NaN       0.000000   \n",
       "75%                  NaN                       NaN       0.000000   \n",
       "max                  NaN                       NaN       1.000000   \n",
       "\n",
       "         severe_toxic        obscene         threat         insult  \\\n",
       "count   159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "unique            NaN            NaN            NaN            NaN   \n",
       "top               NaN            NaN            NaN            NaN   \n",
       "freq              NaN            NaN            NaN            NaN   \n",
       "mean         0.009996       0.052948       0.002996       0.049364   \n",
       "std          0.099477       0.223931       0.054650       0.216627   \n",
       "min          0.000000       0.000000       0.000000       0.000000   \n",
       "25%          0.000000       0.000000       0.000000       0.000000   \n",
       "50%          0.000000       0.000000       0.000000       0.000000   \n",
       "75%          0.000000       0.000000       0.000000       0.000000   \n",
       "max          1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "        identity_hate comment_text_tokenize comment_text_tokenize_stemmed  \\\n",
       "count   159571.000000                159571                        159571   \n",
       "unique            NaN                158250                        158225   \n",
       "top               NaN           ['january']                   ['januari']   \n",
       "freq              NaN                    21                            21   \n",
       "mean         0.008805                   NaN                           NaN   \n",
       "std          0.093420                   NaN                           NaN   \n",
       "min          0.000000                   NaN                           NaN   \n",
       "25%          0.000000                   NaN                           NaN   \n",
       "50%          0.000000                   NaN                           NaN   \n",
       "75%          0.000000                   NaN                           NaN   \n",
       "max          1.000000                   NaN                           NaN   \n",
       "\n",
       "                                       comment_text_clean  \n",
       "count                                              159521  \n",
       "unique                                             157648  \n",
       "top     thank experi wikipedia test work revert remov ...  \n",
       "freq                                                   22  \n",
       "mean                                                  NaN  \n",
       "std                                                   NaN  \n",
       "min                                                   NaN  \n",
       "25%                                                   NaN  \n",
       "50%                                                   NaN  \n",
       "75%                                                   NaN  \n",
       "max                                                   NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fXqX-dNwz5xM"
   },
   "source": [
    "#### Drop NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qV3R-Pr5z5xR"
   },
   "outputs": [],
   "source": [
    "toxic.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MKUN56Akz5xT"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(toxic.loc[:,'comment_text_clean'], toxic.iloc[:,2:8], test_size = .2, random_state = 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create word corpus (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZN_vJx0z5xX"
   },
   "outputs": [],
   "source": [
    "max_features = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCQ7cZxAz5xZ"
   },
   "outputs": [],
   "source": [
    "#TF-IDF Vectors as features\n",
    "\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=max_features)\n",
    "tfidf_vect.fit(x_train)\n",
    "x_train_tfidf =  tfidf_vect.transform(x_train)\n",
    "x_test_tfidf =  tfidf_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cgpWmbrTz5xf"
   },
   "outputs": [],
   "source": [
    "x_train_tfidf_os_all = []\n",
    "y_train_tfidf_os_all = []\n",
    "\n",
    "\n",
    "for i in range(6):   \n",
    "    sm_tfidf = RandomOverSampler(random_state=40)\n",
    "    x_train_tfidf_os, y_train_tfidf_os = sm_tfidf.fit_resample(x_train_tfidf, y_train.iloc[:,i])\n",
    "    x_train_tfidf_os_all.append(x_train_tfidf_os)\n",
    "    y_train_tfidf_os_all.append(y_train_tfidf_os)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BAfcmTZ7z5xi"
   },
   "source": [
    "### Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:33:59.787915Z",
     "start_time": "2018-11-10T21:33:59.578615Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "fd0AQ7adz5xj"
   },
   "outputs": [],
   "source": [
    "data_dim = max_features\n",
    "timesteps = 1\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(timesteps, data_dim), return_sequences=True))\n",
    "  \n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten()) \n",
    "\n",
    "model.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.0022)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.0022)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.0022)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.0022)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:34:08.703288Z",
     "start_time": "2018-11-10T21:34:08.616422Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "6nmaoxGDz5xm"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:34:03.251014Z",
     "start_time": "2018-11-10T21:34:03.237220Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "iL0A4YqSz5xn",
    "outputId": "bb66aa3f-2f04-4ad6-c167-d2618dde6937",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 64)             528640    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 545,345\n",
      "Trainable params: 545,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TLz72MMCz5xp"
   },
   "outputs": [],
   "source": [
    "prediction_train = []\n",
    "prediction_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A440nSi1z5xr"
   },
   "outputs": [],
   "source": [
    "x_test_tfidf = x_test_tfidf.toarray().reshape(x_test_tfidf.shape[0], 1, x_test_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T21:47:44.232376Z",
     "start_time": "2018-11-10T21:39:44.257993Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 897
    },
    "colab_type": "code",
    "id": "3GoDv9Nlz5xv",
    "outputId": "874a57f1-2f2a-481d-ef64-cc469e4f7d50",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 207637 samples, validate on 23071 samples\n",
      "Epoch 1/50\n",
      "207637/207637 [==============================] - 12s 56us/step - loss: 0.3696 - acc: 0.8660 - val_loss: 0.2777 - val_acc: 0.8918\n",
      "Epoch 2/50\n",
      "207637/207637 [==============================] - 9s 44us/step - loss: 0.2662 - acc: 0.9054 - val_loss: 0.3181 - val_acc: 0.8652\n",
      "Epoch 3/50\n",
      "207637/207637 [==============================] - 9s 44us/step - loss: 0.2504 - acc: 0.9086 - val_loss: 0.2697 - val_acc: 0.8786\n",
      "Epoch 4/50\n",
      "207637/207637 [==============================] - 9s 44us/step - loss: 0.2407 - acc: 0.9104 - val_loss: 0.2488 - val_acc: 0.8905\n",
      "Epoch 5/50\n",
      "207637/207637 [==============================] - 9s 44us/step - loss: 0.2331 - acc: 0.9130 - val_loss: 0.2562 - val_acc: 0.8778\n",
      "Epoch 6/50\n",
      "207637/207637 [==============================] - 9s 44us/step - loss: 0.2271 - acc: 0.9139 - val_loss: 0.2562 - val_acc: 0.8806\n",
      "Train on 227395 samples, validate on 25267 samples\n",
      "Epoch 1/50\n",
      "227395/227395 [==============================] - 10s 45us/step - loss: 0.1327 - acc: 0.9679 - val_loss: 0.0685 - val_acc: 0.9965\n",
      "Epoch 2/50\n",
      "227395/227395 [==============================] - 10s 44us/step - loss: 0.1022 - acc: 0.9795 - val_loss: 0.0664 - val_acc: 0.9974\n",
      "Epoch 3/50\n",
      "227395/227395 [==============================] - 10s 44us/step - loss: 0.0912 - acc: 0.9825 - val_loss: 0.0490 - val_acc: 0.9974\n",
      "Epoch 4/50\n",
      "227395/227395 [==============================] - 10s 44us/step - loss: 0.0853 - acc: 0.9843 - val_loss: 0.0530 - val_acc: 0.9974\n",
      "Epoch 5/50\n",
      "227395/227395 [==============================] - 10s 44us/step - loss: 0.0807 - acc: 0.9854 - val_loss: 0.0508 - val_acc: 0.9974\n",
      "Train on 217483 samples, validate on 24165 samples\n",
      "Epoch 1/50\n",
      "217483/217483 [==============================] - 10s 45us/step - loss: 0.1935 - acc: 0.9369 - val_loss: 0.1241 - val_acc: 0.9590\n",
      "Epoch 2/50\n",
      "217483/217483 [==============================] - 10s 45us/step - loss: 0.1490 - acc: 0.9506 - val_loss: 0.1074 - val_acc: 0.9609\n",
      "Epoch 3/50\n",
      "217483/217483 [==============================] - 10s 45us/step - loss: 0.1370 - acc: 0.9539 - val_loss: 0.1058 - val_acc: 0.9763\n",
      "Epoch 4/50\n",
      "217483/217483 [==============================] - 10s 45us/step - loss: 0.1287 - acc: 0.9573 - val_loss: 0.1064 - val_acc: 0.9648\n",
      "Epoch 5/50\n",
      "217483/217483 [==============================] - 10s 45us/step - loss: 0.1241 - acc: 0.9594 - val_loss: 0.0760 - val_acc: 0.9817\n",
      "Epoch 6/50\n",
      "217483/217483 [==============================] - 10s 45us/step - loss: 0.1191 - acc: 0.9615 - val_loss: 0.0804 - val_acc: 0.9813\n",
      "Epoch 7/50\n",
      "217483/217483 [==============================] - 10s 45us/step - loss: 0.1149 - acc: 0.9624 - val_loss: 0.0853 - val_acc: 0.9633\n",
      "Train on 228994 samples, validate on 25444 samples\n",
      "Epoch 1/50\n",
      "228994/228994 [==============================] - 10s 45us/step - loss: 0.1325 - acc: 0.9648 - val_loss: 0.0663 - val_acc: 0.9963\n",
      "Epoch 2/50\n",
      "228994/228994 [==============================] - 10s 45us/step - loss: 0.0746 - acc: 0.9852 - val_loss: 0.0418 - val_acc: 0.9963\n",
      "Epoch 3/50\n",
      "228994/228994 [==============================] - 10s 45us/step - loss: 0.0571 - acc: 0.9901 - val_loss: 0.0333 - val_acc: 0.9963\n",
      "Epoch 4/50\n",
      "228994/228994 [==============================] - 10s 45us/step - loss: 0.0492 - acc: 0.9921 - val_loss: 0.0316 - val_acc: 0.9963\n",
      "Epoch 5/50\n",
      "228994/228994 [==============================] - 10s 45us/step - loss: 0.0443 - acc: 0.9932 - val_loss: 0.0313 - val_acc: 0.9963\n",
      "Epoch 6/50\n",
      "228994/228994 [==============================] - 10s 45us/step - loss: 0.0409 - acc: 0.9936 - val_loss: 0.0295 - val_acc: 0.9963\n",
      "Epoch 7/50\n",
      "228994/228994 [==============================] - 10s 45us/step - loss: 0.0380 - acc: 0.9940 - val_loss: 0.0274 - val_acc: 0.9963\n",
      "Epoch 8/50\n",
      "228994/228994 [==============================] - 10s 45us/step - loss: 0.0352 - acc: 0.9945 - val_loss: 0.0232 - val_acc: 0.9963\n",
      "Epoch 9/50\n",
      "228994/228994 [==============================] - 10s 45us/step - loss: 0.0342 - acc: 0.9947 - val_loss: 0.0229 - val_acc: 0.9963\n",
      "Epoch 10/50\n",
      "228994/228994 [==============================] - 10s 44us/step - loss: 0.0326 - acc: 0.9948 - val_loss: 0.0237 - val_acc: 0.9963\n",
      "Epoch 11/50\n",
      "228994/228994 [==============================] - 10s 44us/step - loss: 0.0312 - acc: 0.9951 - val_loss: 0.0188 - val_acc: 0.9963\n",
      "Epoch 12/50\n",
      "228994/228994 [==============================] - 10s 44us/step - loss: 0.0296 - acc: 0.9952 - val_loss: 0.0230 - val_acc: 0.9963\n",
      "Epoch 13/50\n",
      "228994/228994 [==============================] - 10s 45us/step - loss: 0.0287 - acc: 0.9955 - val_loss: 0.0188 - val_acc: 0.9963\n",
      "Epoch 14/50\n",
      "228994/228994 [==============================] - 10s 45us/step - loss: 0.0288 - acc: 0.9953 - val_loss: 0.0185 - val_acc: 0.9963\n",
      "Epoch 15/50\n",
      "228994/228994 [==============================] - 11s 47us/step - loss: 0.0272 - acc: 0.9957 - val_loss: 0.0185 - val_acc: 0.9963\n",
      "Epoch 16/50\n",
      "228994/228994 [==============================] - 10s 44us/step - loss: 0.0266 - acc: 0.9957 - val_loss: 0.0208 - val_acc: 0.9963\n",
      "Train on 218282 samples, validate on 24254 samples\n",
      "Epoch 1/50\n",
      "218282/218282 [==============================] - 10s 46us/step - loss: 0.3151 - acc: 0.8848 - val_loss: 0.2255 - val_acc: 0.9379\n",
      "Epoch 2/50\n",
      "218282/218282 [==============================] - 10s 45us/step - loss: 0.2231 - acc: 0.9226 - val_loss: 0.1838 - val_acc: 0.9579\n",
      "Epoch 3/50\n",
      "218282/218282 [==============================] - 10s 45us/step - loss: 0.2026 - acc: 0.9311 - val_loss: 0.1684 - val_acc: 0.9854\n",
      "Epoch 4/50\n",
      "218282/218282 [==============================] - 10s 45us/step - loss: 0.1906 - acc: 0.9364 - val_loss: 0.1270 - val_acc: 0.9922\n",
      "Epoch 5/50\n",
      "218282/218282 [==============================] - 10s 45us/step - loss: 0.1800 - acc: 0.9416 - val_loss: 0.1148 - val_acc: 0.9951\n",
      "Epoch 6/50\n",
      "218282/218282 [==============================] - 10s 45us/step - loss: 0.1735 - acc: 0.9440 - val_loss: 0.1148 - val_acc: 0.9950\n",
      "Epoch 7/50\n",
      "218282/218282 [==============================] - 10s 45us/step - loss: 0.1688 - acc: 0.9464 - val_loss: 0.0954 - val_acc: 0.9979\n",
      "Epoch 8/50\n",
      "218282/218282 [==============================] - 10s 45us/step - loss: 0.1641 - acc: 0.9490 - val_loss: 0.1138 - val_acc: 0.9945\n",
      "Epoch 9/50\n",
      "218282/218282 [==============================] - 10s 45us/step - loss: 0.1596 - acc: 0.9512 - val_loss: 0.0934 - val_acc: 0.9974\n",
      "Epoch 10/50\n",
      "218282/218282 [==============================] - 10s 45us/step - loss: 0.1559 - acc: 0.9529 - val_loss: 0.0973 - val_acc: 0.9976\n",
      "Epoch 11/50\n",
      "218282/218282 [==============================] - 10s 45us/step - loss: 0.1519 - acc: 0.9547 - val_loss: 0.1032 - val_acc: 0.9979\n",
      "Train on 227658 samples, validate on 25296 samples\n",
      "Epoch 1/50\n",
      "227658/227658 [==============================] - 10s 45us/step - loss: 0.1974 - acc: 0.9412 - val_loss: 0.0865 - val_acc: 0.9959\n",
      "Epoch 2/50\n",
      "227658/227658 [==============================] - 10s 44us/step - loss: 0.1333 - acc: 0.9646 - val_loss: 0.0741 - val_acc: 0.9967\n",
      "Epoch 3/50\n",
      "227658/227658 [==============================] - 10s 44us/step - loss: 0.1110 - acc: 0.9719 - val_loss: 0.0593 - val_acc: 0.9967\n",
      "Epoch 4/50\n",
      "227658/227658 [==============================] - 10s 44us/step - loss: 0.1009 - acc: 0.9754 - val_loss: 0.0516 - val_acc: 0.9967\n",
      "Epoch 5/50\n",
      "227658/227658 [==============================] - 10s 44us/step - loss: 0.0929 - acc: 0.9782 - val_loss: 0.0544 - val_acc: 0.9970\n",
      "Epoch 6/50\n",
      "227658/227658 [==============================] - 10s 44us/step - loss: 0.0881 - acc: 0.9802 - val_loss: 0.0497 - val_acc: 0.9967\n",
      "Epoch 7/50\n",
      "227658/227658 [==============================] - 10s 44us/step - loss: 0.0823 - acc: 0.9816 - val_loss: 0.0432 - val_acc: 0.9975\n",
      "Epoch 8/50\n",
      "227658/227658 [==============================] - 10s 44us/step - loss: 0.0784 - acc: 0.9826 - val_loss: 0.0427 - val_acc: 0.9975\n",
      "Epoch 9/50\n",
      "227658/227658 [==============================] - 10s 44us/step - loss: 0.0766 - acc: 0.9833 - val_loss: 0.0382 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "227658/227658 [==============================] - 10s 45us/step - loss: 0.0729 - acc: 0.9844 - val_loss: 0.0430 - val_acc: 0.9970\n",
      "Epoch 11/50\n",
      "227658/227658 [==============================] - 10s 44us/step - loss: 0.0700 - acc: 0.9853 - val_loss: 0.0418 - val_acc: 0.9967\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n",
    "             ModelCheckpoint(filepath='best_model' + str(i) +'2000.h5', monitor='val_loss', save_best_only=True)]\n",
    "    \n",
    "    x_train_tfidf_os = x_train_tfidf_os_all[i]\n",
    "    x_train_tfidf_os = x_train_tfidf_os.toarray().reshape(x_train_tfidf_os.shape[0], 1, x_train_tfidf_os.shape[1])\n",
    "    history = model.fit(x_train_tfidf_os, y_train_tfidf_os_all[i],\n",
    "              batch_size=128, epochs=50, callbacks=callbacks,\n",
    "              verbose=1,\n",
    "              validation_split=0.1)\n",
    "    model.save('my_model' + str(i) +'2000.h5')\n",
    "    prediction_train.append(model.predict_proba(x_train_tfidf.toarray().reshape(x_train_tfidf.shape[0], 1, x_train_tfidf.shape[1])))\n",
    "    prediction_test.append(model.predict_proba(x_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4XaKamnNz5x2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prediction_submission_array = np.asarray(prediction_test).reshape(6, 31905).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MzTs0QKKz5x4"
   },
   "outputs": [],
   "source": [
    "proba = pd.DataFrame(data=prediction_submission_array,columns=['toxic','severe_toxic','obscene','threat','insult','identity_hate'], index=x_test.index.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nPxAj9K7z5x6"
   },
   "outputs": [],
   "source": [
    "proba.to_csv('submission_2000_max_feature.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "KgJP7z3Lz5x7",
    "outputId": "4d1060c5-6a74-43a5-8e4a-44c40bcf787c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "f1_train = []\n",
    "cutoff = []\n",
    "for i in range(6):\n",
    "    best_f1 = 0\n",
    "    best_val = 0\n",
    "    for val in np.arange(0,1,0.001):\n",
    "        if f1_score(y_train.iloc[:,i], prediction_train[i] > val) > best_f1:\n",
    "            best_f1 = f1_score(y_train.iloc[:,i], prediction_train[i] > val)\n",
    "            best_val = val\n",
    "    f1_train.append(best_f1)\n",
    "    cutoff.append(best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "-Qra_kPzz5x-",
    "outputId": "e160ddf2-95db-490b-c08e-759968e59684",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7911528674887454,\n",
       " 0.5366276549631557,\n",
       " 0.8583448275862069,\n",
       " 0.8708240534521158,\n",
       " 0.7718204488778055,\n",
       " 0.7387826086956522]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_gp6uWQ3z5yC",
    "outputId": "24c8fbc1-09ea-4184-9bb4-c481f63d8f5a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.748, 0.967, 0.887, 0.994, 0.88, 0.974]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "bsp9H1FQz5yF",
    "outputId": "f4619bcc-c754-4e9b-c2cb-fffa3d08abf3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1_test = [f1_score(y_test.iloc[:,i] , prediction_test[i] > cutoff[i]) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7345302981724912,\n",
       " 0.4293577981651376,\n",
       " 0.784077892325315,\n",
       " 0.3057324840764331,\n",
       " 0.6951111111111111,\n",
       " 0.5032258064516129]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mshzyR1z5yH"
   },
   "outputs": [],
   "source": [
    "roc_auc_train = [roc_auc_score(y_train.iloc[:,i], prediction_train[i]) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfQ8Wjm8z5yJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc_auc_test = [roc_auc_score(y_test.iloc[:,i], prediction_test[i]) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "SrSJE3FEz5yL",
    "outputId": "9c193a15-c32d-4231-c0fc-917dea2b5a9f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9791480961754042,\n",
       " 0.992160191125364,\n",
       " 0.995378190586399,\n",
       " 0.9995809008060695,\n",
       " 0.990819916269545,\n",
       " 0.9975233431935068]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "m7LIiogez5yM",
    "outputId": "f33c402c-b32b-42b5-c652-4ccc73b62c8b",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9537939303292271,\n",
       " 0.9721864933712461,\n",
       " 0.9706205905651881,\n",
       " 0.9278813179276142,\n",
       " 0.9623815887314571,\n",
       " 0.9460900188142216]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_test"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Toxic_Comment_Classification_Neural_Network_100.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
